{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streetview import search_panoramas\n",
    "import folium\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "from sampled_already import sampled_already\n",
    "from long_lat_multifamily_la2 import longitude_latitude_dict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PanoramaGroupFinder:\n",
    "    def __init__(self, latitude, longitude, search_grid_diameter_meters, search_grid_nxn, pano_ids_already_set):\n",
    "        self.longitude = longitude\n",
    "        self.latitude = latitude\n",
    "        self.search_gridcell_meters = search_grid_diameter_meters//search_grid_nxn\n",
    "        self.search_gridcell_nxn = search_grid_nxn\n",
    "        self.pano_ids_already_set = pano_ids_already_set\n",
    "\n",
    "    \n",
    "    def find_nearby(self, lat, lon, lats_ls, lons_ls, panoid_ls):\n",
    "      try:\n",
    "        panos = search_panoramas(lat=lat, lon=lon)\n",
    "        \n",
    "        for pano in panos[:100]:\n",
    "            lats_ls.append(pano.lat)\n",
    "            lons_ls.append(pano.lon)\n",
    "            panoid_ls.append(pano.pano_id)\n",
    "      except IndexError:\n",
    "        # Handle the case when no panoramas are found or the API returns unexpected data\n",
    "        print(f\"No panoramas found or error in API response at coordinates: {lat}, {lon}\")\n",
    "      except Exception as e:\n",
    "        # Handle other potential errors\n",
    "        print(f\"Error searching panoramas at {lat}, {lon}: {str(e)}\")\n",
    "        \n",
    "      return lats_ls, lons_ls, panoid_ls\n",
    "\n",
    "    \n",
    "    def get_all_panos(self):\n",
    "      lats_ls, lons_ls, panoid_ls = [], [], []\n",
    "\n",
    "\n",
    "      north = geodesic(meters=self.search_gridcell_meters).destination((self.latitude, self.longitude), 0)\n",
    "      east = geodesic(meters=self.search_gridcell_meters).destination((self.latitude, self.longitude), 90)\n",
    "      # calculate grid cell sizes \n",
    "      search_grid_lat = north.latitude - self.latitude\n",
    "      search_grid_lon = east.longitude - self.longitude\n",
    "      \n",
    "\n",
    "      for i in range(int(-self.search_gridcell_nxn//2), int(self.search_gridcell_nxn//2) + 1):\n",
    "        for j in range(int(-self.search_gridcell_nxn//2), int(self.search_gridcell_nxn//2) + 1):\n",
    "            lat = self.latitude + (i * search_grid_lat)\n",
    "            lon = self.longitude + (j * search_grid_lon)\n",
    "            lats_ls, lons_ls, panoid_ls = self.find_nearby(lat, lon, lats_ls, lons_ls, panoid_ls)\n",
    "      \n",
    "      return lats_ls, lons_ls, panoid_ls\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "    def get_groupings(self):\n",
    "      lats_ls, lons_ls, panoid_ls = self.get_all_panos()\n",
    "      print(f\"found {len(panoid_ls)} different panos\")\n",
    "      # grouping_dict = self.create_groupings(lats_ls, lons_ls, panoid_ls)\n",
    "    #   print(grouping_dict)\n",
    "      # Create new lists to store filtered results\n",
    "      filtered_panoid_ls = []\n",
    "      filtered_lats_ls = []\n",
    "      filtered_lons_ls = []\n",
    "      \n",
    "      # Iterate through all panoramas and only keep those not already in the set\n",
    "      for i, panoid in enumerate(panoid_ls):\n",
    "          if panoid not in self.pano_ids_already_set:\n",
    "              filtered_panoid_ls.append(panoid)\n",
    "              filtered_lats_ls.append(lats_ls[i])\n",
    "              filtered_lons_ls.append(lons_ls[i])\n",
    "      \n",
    "      # Replace the original lists with the filtered ones\n",
    "      # lats_ls, lons_ls, panoid_ls = filtered_lats_ls, filtered_lons_ls, filtered_panoid_ls\n",
    "\n",
    "      return filtered_lats_ls, filtered_lons_ls, filtered_panoid_ls\n",
    "      \n",
    "\n",
    "\n",
    "      # Save grouping_dict to a Python file\n",
    "      # with open('test_grouping_dict200_2.py', 'w') as f:\n",
    "      #     f.write('grouping_dict = {\\n')\n",
    "      #     for key, value in grouping_dict.items():\n",
    "      #         f.write(f\"    '{key}': {value},\\n\")\n",
    "      #     f.write('}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an empty DataFrame with the required columns\n",
    "# panos_df = pd.DataFrame(columns=['pano_id', 'lat', 'lon'])\n",
    "\n",
    "# # Save the empty DataFrame to CSV\n",
    "# csv_save_file = \"panos.csv\"\n",
    "# panos_df.to_csv(csv_save_file, index=False)\n",
    "\n",
    "# print(f\"Created empty CSV file: {csv_save_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_save_file = \"panos.csv\"\n",
    "panos_df = pd.read_csv(csv_save_file)\n",
    "\n",
    "# This will be used to check for already sampled panoramas\n",
    "pano_ids_already_set = set(panos_df['pano_id'])\n",
    "# Get the number of panoramas already sampled\n",
    "num_already_sampled = len(sampled_already)\n",
    "num_locations_total = len(longitude_latitude_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "counter = 0\n",
    "for coords in longitude_latitude_dict.values():\n",
    "#   if counter > 10:\n",
    "#       break\n",
    "  \n",
    "  \n",
    "  lat = coords[0]\n",
    "  lon = coords[1]\n",
    "\n",
    "\n",
    "  if (lat, lon) in sampled_already:\n",
    "      print(\"skip\")\n",
    "      continue\n",
    "  \n",
    "  \n",
    "  counter += 1\n",
    "  print(f\"through {num_already_sampled} locations, {(num_already_sampled/num_locations_total * 100):.2f}% done\")\n",
    "  print(f\"searching for panos around {lat, lon}\")\n",
    "  num_already_sampled += 1\n",
    "\n",
    "  # Update sampled_already.py with the current coordinates\n",
    "\n",
    "  lats_ls, lons_ls, panoid_ls = PanoramaGroupFinder(latitude = lat, longitude= lon, search_grid_diameter_meters = 1200, search_grid_nxn = 6, pano_ids_already_set = pano_ids_already_set).get_groupings()\n",
    "  \n",
    "  for panoid in panoid_ls:\n",
    "    # Add each new panorama ID to the set of already sampled panoramas\n",
    "    pano_ids_already_set.add(panoid)\n",
    "\n",
    "  # Create a temporary DataFrame with the new panorama data\n",
    "  new_panos_df = pd.DataFrame({\n",
    "      'pano_id': panoid_ls,\n",
    "      'lat': lats_ls,\n",
    "      'lon': lons_ls\n",
    "  })\n",
    "  \n",
    "  # Append the new data to the existing DataFrame\n",
    "#   panos_df = pd.concat([panos_df, new_panos_df], ignore_index=True)\n",
    "  \n",
    "  # Save the updated DataFrame back to the CSV file\n",
    "  new_panos_df.to_csv(csv_save_file, mode='a', header=False, index=False)\n",
    "  \n",
    "  print(f\"Added {len(panoid_ls)} new panoramas to {csv_save_file}\")\n",
    "\n",
    "  sampled_already.add((lat, lon))\n",
    "  with open(\"sampled_already.py\", \"w\") as f:\n",
    "      f.write(f\"sampled_already = {sampled_already}\\n\")\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# checked_locations = sampled_already\n",
    "# if         \n",
    "#   return (lat, lon) in checked_locations\n",
    "\n",
    "\n",
    "# PanoramaGroupFinder(latitude = 34.272, longitude= -118.484869, search_grid_diameter_meters = 200, search_grid_nxn = 2, grouping_radius_threshold = 5).get_groupings()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
