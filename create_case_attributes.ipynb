{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "import spacy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names\n",
    "#names count\n",
    "\n",
    "def extract_name(text):\n",
    "  name_ls = []\n",
    "  names_count = 0\n",
    "  matches = re.findall(r'my name is (\\w+) (\\w+)', text, re.IGNORECASE)\n",
    "  for match in matches:\n",
    "    name_ls.append(match)\n",
    "    names_count += 1\n",
    "    \n",
    "  return name_ls, names_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parking\n",
    "#affordability\n",
    "#community\n",
    "#total words\n",
    "\n",
    "def extract_keywords(text):\n",
    "  words = text.split()\n",
    "  words_count = len(words)\n",
    "\n",
    "  word_hash = {}\n",
    "  for word in words:\n",
    "    if word not in word_hash:\n",
    "        word_hash[word] = 1\n",
    "    else:\n",
    "        word_hash[word] += 1\n",
    "\n",
    "  parking_count = 0\n",
    "  if \"parking\" in word_hash:\n",
    "     parking_count = word_hash[\"parking\"]\n",
    "  if \"Parking\" in word_hash:\n",
    "     parking_count = word_hash[\"Parking\"]\n",
    " \n",
    "\n",
    "  affordable_count = 0\n",
    "  if \"affordability\" in word_hash:\n",
    "     affordable_count = word_hash[\"affordability\"]\n",
    "  if \"affordable\" in word_hash:\n",
    "     affordable_count += word_hash[\"affordable\"]\n",
    "  if \"Affordability\" in word_hash:\n",
    "     affordable_count = word_hash[\"Affordability\"]\n",
    "  if \"Affordable\" in word_hash:\n",
    "     affordable_count += word_hash[\"Affordable\"]\n",
    "     \n",
    "\n",
    "  community_count = 0\n",
    "  if \"community\" in word_hash:\n",
    "     community_count = word_hash[\"community\"]\n",
    "  if \"communities\" in word_hash:\n",
    "     community_count += word_hash[\"communities\"]\n",
    "  if \"Community\" in word_hash:\n",
    "     community_count = word_hash[\"Community\"]\n",
    "  if \"Communities\" in word_hash:\n",
    "     community_count += word_hash[\"Communities\"]\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "  return words_count, parking_count, affordable_count, community_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#sentiment\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "def get_sentiment(text):\n",
    "  encoded_input = tokenizer(text, return_tensors='pt')\n",
    "  # print(encoded_input['input_ids'].size())\n",
    "  output = model(**encoded_input)\n",
    "  scores = output[0][0].detach().numpy()\n",
    "  scores = softmax(scores)\n",
    "\n",
    "  return scores[0], scores[1], scores[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text minus stop words\n",
    "#text minus stop word count \n",
    "\n",
    "def remove_stop_words(text):\n",
    "  words = text.split()\n",
    "  non_stop_words_count = 0\n",
    "  nlp = spacy.load(\"en_core_web_sm\")\n",
    "  stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "  for i in range(len(words)):\n",
    "     if words[i] not in stop_words:\n",
    "        non_stop_words_count += 1\n",
    "  return non_stop_words_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_hyperlinks_df = pd.read_csv(\"cleaned_hyperlinks.csv\")\n",
    "case_to_df = {}\n",
    "\n",
    "collapsed_df = cleaned_hyperlinks_df.groupby(['clean_file_name', 'case_name'])['audio_file_name'].agg(list).reset_index()\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=['case_name', 'CEQA', 'names', 'names_count', 'parking_mentions', 'affordability_mentions', 'community_mentions', 'num_words', 'num_nonstopgap_words', 'sentiment_pos', 'sentiment_neg', 'sentiment_neutral', 'date', 'area', 'txt_file_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_file_name</th>\n",
       "      <th>case_name</th>\n",
       "      <th>audio_file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-05-10audio</td>\n",
       "      <td>01DepartmentalRepor</td>\n",
       "      <td>[01-05-10audio_01DepartmentalReport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-05-10audio</td>\n",
       "      <td>02CommissionBusines</td>\n",
       "      <td>[01-05-10audio_02CommissionBusiness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-05-10audio</td>\n",
       "      <td>03ZA09-2885&amp;04ZA09-2886</td>\n",
       "      <td>[01-05-10audio_03ZA09-2885_04ZA09-2886a, 01-05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-05-10audio</td>\n",
       "      <td>04ZA09-2886</td>\n",
       "      <td>[01-05-10audio_04ZA09-2886]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-05-10audio</td>\n",
       "      <td>05APCW10-657</td>\n",
       "      <td>[01-05-10audio_05APCW10-657]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>WLA12-05-12audio</td>\n",
       "      <td>04PublicCommentPerio</td>\n",
       "      <td>[WLA12-05-12audio_04PublicCommentPeriod]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2678</th>\n",
       "      <td>WLA12-07-11audio</td>\n",
       "      <td>01DepartmentalRepor</td>\n",
       "      <td>[WLA12-07-11audio_01DepartmentalReport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>WLA12-07-11audio</td>\n",
       "      <td>02CommissionBusines</td>\n",
       "      <td>[WLA12-07-11audio_02CommissionBusiness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>WLA12-07-11audio</td>\n",
       "      <td>03ZA11-1481</td>\n",
       "      <td>[WLA12-07-11audio_03ZA11-1481]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681</th>\n",
       "      <td>WLA12-07-11audio</td>\n",
       "      <td>04DIR10-2280</td>\n",
       "      <td>[WLA12-07-11audio_04DIR10-2280]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2682 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       clean_file_name                case_name  \\\n",
       "0        01-05-10audio      01DepartmentalRepor   \n",
       "1        01-05-10audio      02CommissionBusines   \n",
       "2        01-05-10audio  03ZA09-2885&04ZA09-2886   \n",
       "3        01-05-10audio              04ZA09-2886   \n",
       "4        01-05-10audio             05APCW10-657   \n",
       "...                ...                      ...   \n",
       "2677  WLA12-05-12audio     04PublicCommentPerio   \n",
       "2678  WLA12-07-11audio      01DepartmentalRepor   \n",
       "2679  WLA12-07-11audio      02CommissionBusines   \n",
       "2680  WLA12-07-11audio              03ZA11-1481   \n",
       "2681  WLA12-07-11audio             04DIR10-2280   \n",
       "\n",
       "                                        audio_file_name  \n",
       "0                  [01-05-10audio_01DepartmentalReport]  \n",
       "1                  [01-05-10audio_02CommissionBusiness]  \n",
       "2     [01-05-10audio_03ZA09-2885_04ZA09-2886a, 01-05...  \n",
       "3                           [01-05-10audio_04ZA09-2886]  \n",
       "4                          [01-05-10audio_05APCW10-657]  \n",
       "...                                                 ...  \n",
       "2677           [WLA12-05-12audio_04PublicCommentPeriod]  \n",
       "2678            [WLA12-07-11audio_01DepartmentalReport]  \n",
       "2679            [WLA12-07-11audio_02CommissionBusiness]  \n",
       "2680                     [WLA12-07-11audio_03ZA11-1481]  \n",
       "2681                    [WLA12-07-11audio_04DIR10-2280]  \n",
       "\n",
       "[2682 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapsed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_rows = cleaned_hyperlinks_df[(cleaned_hyperlinks_df['clean_file_name'] == \"07-12-2012audio\") & (cleaned_hyperlinks_df['case_name'] == \"01DirectorsRepor\")]\n",
    "\n",
    "# date = filtered_rows.loc[0, 'hearing_date']\n",
    "# area = filtered_rows.loc[0, 'area']\n",
    "# area\n",
    "# date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt/01-05-10audio_01DepartmentalReport.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt/01-05-10audio_02CommissionBusiness.txt\n",
      "txt/01-05-10audio_03ZA09-2885_04ZA09-2886b.txt\n",
      "txt/01-05-10audio_04ZA09-2886.txt\n",
      "txt/01-05-10audio_05APCW10-657.txt\n",
      "txt/01-05-10audio_06APCW10-2130.txt\n",
      "txt/01-05-10audio_07ZA07-5584b.txt\n",
      "txt/01-09-13audio_01DepartmentalReport.txt\n",
      "txt/01-09-13audio_02CommissionBusiness.txt\n",
      "txt/01-09-13audio_03APCE12-1723b.txt\n",
      "txt/01-09-13audio_04PublicCommentPeriod.txt\n",
      "txt/01-10-2017audio_1 DirRpt.txt\n",
      "txt/01-10-2017audio_2 CommBus.txt\n",
      "txt/01-10-2017audio_3 NCP.txt\n",
      "txt/01-10-2017audio_4 VTT-72513.txt\n",
      "txt/01-10-2017audio_5 PubCom.txt\n",
      "txt/01-11-2011audio_01DirectorsReport.txt\n",
      "txt/01-11-2011audio_02CommissionBusiness.txt\n",
      "txt/01-11-2011audio_03ZA08-3851.txt\n",
      "txt/01-11-2011audio_04ZA09-4164b.txt\n",
      "txt/01-11-2011audio_05ZA09-2116.txt\n",
      "txt/01-11-2011audio_06ZA09-1185.txt\n",
      "txt/01-11-2011audio_07DIR10-1338b.txt\n",
      "txt/01-11-2017audio_1 DirRpt.txt\n",
      "txt/01-11-2017audio_2 CommBus.txt\n",
      "txt/01-11-2017audio_3 NCP.txt\n",
      "txt/01-11-2017audio_4 ZA-2015-1109.txt\n",
      "txt/01-11-2017audio_5 ZA-2016-1638.txt\n",
      "txt/01-11-2017audio_6 VTT-74164.txt\n",
      "txt/01-11-2017audio_7 VTT-74301.txt\n",
      "txt/01-11-2017audio_8 PubCom.txt\n",
      "txt/01-12-17audio_1 Dir Rpt.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 114\u001b[0m\n\u001b[1;32m    111\u001b[0m file_name_save \u001b[38;5;241m=\u001b[39m file_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m#   negative, neutral, pos = get_sentiment(text)\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m non_stop_words_count \u001b[38;5;241m=\u001b[39m \u001b[43mremove_stop_words\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m new_row \u001b[38;5;241m=\u001b[39m [case_name, ceqa, name_ls, names_count, parking_count, affordable_count, community_count, words_count, non_stop_words_count, pos, negative, neutral, date, area, file_name_save]\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m#df = df.append(pd.Series(new_row, index=df.columns), ignore_index=True)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[50], line 7\u001b[0m, in \u001b[0;36mremove_stop_words\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      5\u001b[0m words \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m      6\u001b[0m non_stop_words_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 7\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m stop_words \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mlang\u001b[38;5;241m.\u001b[39men\u001b[38;5;241m.\u001b[39mstop_words\u001b[38;5;241m.\u001b[39mSTOP_WORDS\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(words)):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/util.py:465\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_lang_class(name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblank:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))()\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_package(name):  \u001b[38;5;66;03m# installed as package\u001b[39;00m\n\u001b[0;32m--> 465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_package\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(name)\u001b[38;5;241m.\u001b[39mexists():  \u001b[38;5;66;03m# path to model data directory\u001b[39;00m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/util.py:501\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03mname (str): The package name.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;124;03mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(name)\n\u001b[0;32m--> 501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/en_core_web_sm/__init__.py:10\u001b[0m, in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moverrides):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_init_py\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;18;43m__file__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/util.py:682\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m    681\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE052\u001b[38;5;241m.\u001b[39mformat(path\u001b[38;5;241m=\u001b[39mdata_path))\n\u001b[0;32m--> 682\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/util.py:547\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    538\u001b[0m config \u001b[38;5;241m=\u001b[39m load_config(config_path, overrides\u001b[38;5;241m=\u001b[39moverrides)\n\u001b[1;32m    539\u001b[0m nlp \u001b[38;5;241m=\u001b[39m load_model_from_config(\n\u001b[1;32m    540\u001b[0m     config,\n\u001b[1;32m    541\u001b[0m     vocab\u001b[38;5;241m=\u001b[39mvocab,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m     meta\u001b[38;5;241m=\u001b[39mmeta,\n\u001b[1;32m    546\u001b[0m )\n\u001b[0;32m--> 547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/language.py:2209\u001b[0m, in \u001b[0;36mLanguage.from_disk\u001b[0;34m(self, path, exclude, overrides)\u001b[0m\n\u001b[1;32m   2206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexists() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude:  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;66;03m# Convert to list here in case exclude is (default) tuple\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     exclude \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(exclude) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m-> 2209\u001b[0m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeserializers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   2210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m path  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   2211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_link_components()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/util.py:1390\u001b[0m, in \u001b[0;36mfrom_disk\u001b[0;34m(path, readers, exclude)\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, reader \u001b[38;5;129;01min\u001b[39;00m readers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1388\u001b[0m     \u001b[38;5;66;03m# Split to support file names like meta.json\u001b[39;00m\n\u001b[1;32m   1389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude:\n\u001b[0;32m-> 1390\u001b[0m         \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/language.py:2195\u001b[0m, in \u001b[0;36mLanguage.from_disk.<locals>.<lambda>\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m   2193\u001b[0m deserializers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta.json\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m deserialize_meta  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   2194\u001b[0m deserializers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m deserialize_vocab  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m-> 2195\u001b[0m deserializers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m p: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[union-attr]\u001b[39;49;00m\n\u001b[1;32m   2196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvocab\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2197\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2198\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, proc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_components:\n\u001b[1;32m   2199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m exclude:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/tokenizer.pyx:778\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer.from_disk\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/tokenizer.pyx:846\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer.from_bytes\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/tokenizer.pyx:123\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer.rules.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/tokenizer.pyx:571\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer._load_special_cases\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/tokenizer.pyx:615\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer.add_special_case\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/tokenizer.pyx:199\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer._tokenize_affixes\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/tokenizer.pyx:391\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer._tokenize\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/tokenizer.pyx:470\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer._attach_tokens\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/vocab.pyx:165\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab.get\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/vocab.pyx:202\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab._new_lexeme\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/lang/lex_attrs.py:144\u001b[0m, in \u001b[0;36mlower\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m    140\u001b[0m             shape\u001b[38;5;241m.\u001b[39mappend(shape_char)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(shape)\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlower\u001b[39m(string: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m string\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprefix\u001b[39m(string: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#merge txt\n",
    "#load in df\n",
    "def get_date_location(clean_file_name, case_name):\n",
    "\n",
    "  filtered_rows = cleaned_hyperlinks_df[(cleaned_hyperlinks_df['clean_file_name'] == clean_file_name) & (cleaned_hyperlinks_df['case_name'] == case_name)]\n",
    "\n",
    "  date = filtered_rows.iloc[0]['hearing_date']\n",
    "  area = filtered_rows.iloc[0]['area']\n",
    "\n",
    "  return date, area\n",
    "\n",
    "\n",
    "def get_ceqa(clean_file_name, case_name):\n",
    "  filtered_rows = cleaned_hyperlinks_df[(cleaned_hyperlinks_df['clean_file_name'] == clean_file_name) & (cleaned_hyperlinks_df['case_name'] == case_name)]\n",
    "  text_vals = filtered_rows['Text'].tolist()\n",
    "\n",
    "  pattern = r\"CEQA:\\s*([\\w-]+)\"\n",
    "\n",
    "  for text in text_vals:\n",
    "    match = re.search(pattern, str(text))\n",
    "\n",
    "    if match:\n",
    "      code = match.group(1)\n",
    "      return code\n",
    " \n",
    "  \n",
    "  return np.NaN\n",
    "\n",
    "def split_text(text, chunk_size=1500):\n",
    "    # words = text.split()  # Split the text into individual words\n",
    "    # chunks = []\n",
    "    # current_chunk = []  # Initialize an empty list to hold the words in the current chunk\n",
    "    # word_count = 0  # Initialize a counter for the number of words in the current chunk\n",
    "    \n",
    "    # # Iterate over the words in the text\n",
    "    # for word in words:\n",
    "    #     current_chunk.append(word)  # Add the word to the current chunk\n",
    "    #     word_count += 1  # Increment the word count\n",
    "        \n",
    "    #     # If the word count reaches the chunk size or if it's the last word\n",
    "    #     if word_count == chunk_size or word == words[-1]:\n",
    "    #         # Add the current chunk to the list of chunks\n",
    "    #         chunks.append(' '.join(current_chunk))\n",
    "    #         current_chunk = []  # Reset the current chunk\n",
    "    #         word_count = 0  # Reset the word count\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), chunk_size):\n",
    "        chunk = text[i:i+chunk_size]\n",
    "        chunks.append(chunk)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "for index, row in collapsed_df.iterrows():\n",
    "  file_names = row['audio_file_name']\n",
    "  clean_file_name = row['clean_file_name']\n",
    "  case_name = row['case_name']\n",
    "\n",
    "  ceqa = get_ceqa(clean_file_name, case_name)\n",
    "  date, area = get_date_location(clean_file_name, case_name)\n",
    "  text = \" \"\n",
    "  for file in file_names:\n",
    "    file_name = 'txt/' + file + '.txt'\n",
    "    if os.path.exists(file_name):\n",
    "      with open(file_name, 'r') as file:\n",
    "        this_file_text = file.read()\n",
    "        text += this_file_text\n",
    "  print(file_name)\n",
    "  name_ls, names_count = extract_name(text)\n",
    "  words_count, parking_count, affordable_count, community_count = extract_keywords(text)\n",
    "  # if words_count > 300:\n",
    "  #   length = len(text)\n",
    "  #   negative, neutral, pos = get_sentiment(text[0:500])\n",
    "  #   all_vals_array = np.array([negative, neutral, pos])\n",
    "  #   for i in range(500, length, 500):\n",
    "  #     negative, neutral, pos = get_sentiment(text)\n",
    "  #     this_vals_array = np.array([negative, neutral, pos])\n",
    "  #     all_vals_array = np.vstack((all_vals_array, this_vals_array))\n",
    "  #   means_array = np.mean(all_vals_array, axis=1)\n",
    "  #   negative, neutral, pos = means_array[0], means_array[1], means_array[2]\n",
    "  \n",
    "  chunks = split_text(text)\n",
    "  negative_ls = []\n",
    "  neutral_ls = []\n",
    "  pos_ls = []\n",
    "  for i in range(len(chunks)):\n",
    "    # encoded_input = tokenizer(chunks[i], return_tensors='pt')\n",
    "    # output = model(**encoded_input)\n",
    "    # scores = output[0][0].detach().numpy()\n",
    "    # scores = softmax(scores)\n",
    "\n",
    "    # negative, neutral, pos = scores[0], scores[1], scores[2]\n",
    "    # print(len)\n",
    "    negative, neutral, pos = get_sentiment(chunks[i])\n",
    "    negative_ls.append(negative)\n",
    "    neutral_ls.append(neutral)\n",
    "    pos_ls.append(pos)\n",
    "\n",
    "\n",
    "  negative = np.mean(negative_ls)\n",
    "  neutral = np.mean(neutral_ls)\n",
    "  pos = np.mean(pos_ls)\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  file_name_save = clean_file_name+case_name+\".txt\"\n",
    "  file_name_save = file_name.replace(\" \", \"\")\n",
    "  # else:\n",
    "  #   negative, neutral, pos = get_sentiment(text)\n",
    "  non_stop_words_count = remove_stop_words(text)\n",
    "      \n",
    "  new_row = [case_name, ceqa, name_ls, names_count, parking_count, affordable_count, community_count, words_count, non_stop_words_count, pos, negative, neutral, date, area, file_name_save]\n",
    "  #df = df.append(pd.Series(new_row, index=df.columns), ignore_index=True)\n",
    "  df.loc[len(df)] = new_row\n",
    "  df.to_csv('cases.tsv', sep='\\t',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_name</th>\n",
       "      <th>CEQA</th>\n",
       "      <th>names</th>\n",
       "      <th>names_count</th>\n",
       "      <th>parking_mentions</th>\n",
       "      <th>affordability_mentions</th>\n",
       "      <th>community_mentions</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_nonstopgap_words</th>\n",
       "      <th>sentiment_pos</th>\n",
       "      <th>sentiment_neg</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>date</th>\n",
       "      <th>area</th>\n",
       "      <th>txt_file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 DirRp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "      <td>178</td>\n",
       "      <td>0.433737</td>\n",
       "      <td>0.023680</td>\n",
       "      <td>0.542582</td>\n",
       "      <td>1/25/17</td>\n",
       "      <td>East</td>\n",
       "      <td>txt/01-25-2017audio_1DirRpt.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 CommBu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>187</td>\n",
       "      <td>0.195975</td>\n",
       "      <td>0.032334</td>\n",
       "      <td>0.771691</td>\n",
       "      <td>1/25/17</td>\n",
       "      <td>East</td>\n",
       "      <td>txt/01-25-2017audio_2CommBus.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 NC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>21</td>\n",
       "      <td>0.180984</td>\n",
       "      <td>0.064153</td>\n",
       "      <td>0.754864</td>\n",
       "      <td>1/25/17</td>\n",
       "      <td>East</td>\n",
       "      <td>txt/01-25-2017audio_3NCP.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 VTT-74301+PubCo</td>\n",
       "      <td>ENV-2016-1898-CE</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.270926</td>\n",
       "      <td>0.058704</td>\n",
       "      <td>0.670370</td>\n",
       "      <td>1/25/17</td>\n",
       "      <td>East</td>\n",
       "      <td>txt/01-25-2017audio_4VTT-74301+PubCom.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DirectorsRepor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(Bill, Rochen)]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2739</td>\n",
       "      <td>1356</td>\n",
       "      <td>0.341688</td>\n",
       "      <td>0.038798</td>\n",
       "      <td>0.619515</td>\n",
       "      <td>7/12/12</td>\n",
       "      <td>CPC</td>\n",
       "      <td>txt/07-12-2012audio_01DirectorsReport.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>02CommissionBusines</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4270</td>\n",
       "      <td>2106</td>\n",
       "      <td>0.337581</td>\n",
       "      <td>0.077420</td>\n",
       "      <td>0.584999</td>\n",
       "      <td>7/12/12</td>\n",
       "      <td>CPC</td>\n",
       "      <td>txt/07-12-2012audio_02CommissionBusiness.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>03PublicCommentPerio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(Armando, Herman)]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>390</td>\n",
       "      <td>208</td>\n",
       "      <td>0.445862</td>\n",
       "      <td>0.013924</td>\n",
       "      <td>0.540214</td>\n",
       "      <td>7/12/12</td>\n",
       "      <td>CPC</td>\n",
       "      <td>txt/07-12-2012audio_03PublicCommentPeriod.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>04CPC08-2142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(Rigoberto, Urtado), (Anna, C), (Isabel, Roja...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28822</td>\n",
       "      <td>14536</td>\n",
       "      <td>0.194725</td>\n",
       "      <td>0.166172</td>\n",
       "      <td>0.639103</td>\n",
       "      <td>7/12/12</td>\n",
       "      <td>CPC</td>\n",
       "      <td>txt/07-12-2012audio_04CPC08-2142f.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>05CPC12-1504</td>\n",
       "      <td>ENV-2012-1505-CE</td>\n",
       "      <td>[(George, U), (King, Chung), (Tari, Statelyn),...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>16639</td>\n",
       "      <td>8698</td>\n",
       "      <td>0.233360</td>\n",
       "      <td>0.172151</td>\n",
       "      <td>0.594489</td>\n",
       "      <td>7/12/12</td>\n",
       "      <td>CPC</td>\n",
       "      <td>txt/07-12-2012audio_05CPC12-1504c.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1 DepRp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(Harden, Carter)]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1402</td>\n",
       "      <td>714</td>\n",
       "      <td>0.296306</td>\n",
       "      <td>0.028725</td>\n",
       "      <td>0.674969</td>\n",
       "      <td>7/20/16</td>\n",
       "      <td>West</td>\n",
       "      <td>txt/WLA07-20-16audio_1DepRpt.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2 CommBu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(Larry, Larson)]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1940</td>\n",
       "      <td>977</td>\n",
       "      <td>0.283531</td>\n",
       "      <td>0.086860</td>\n",
       "      <td>0.629609</td>\n",
       "      <td>7/20/16</td>\n",
       "      <td>West</td>\n",
       "      <td>txt/WLA07-20-16audio_2CommBus.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3 NC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>41</td>\n",
       "      <td>0.047930</td>\n",
       "      <td>0.012037</td>\n",
       "      <td>0.940033</td>\n",
       "      <td>7/20/16</td>\n",
       "      <td>West</td>\n",
       "      <td>txt/WLA07-20-16audio_3NCP.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4 DIR-2015-1282-DR</td>\n",
       "      <td>ENV-2015-1283-CE</td>\n",
       "      <td>[(Harden, Carter)]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26434</td>\n",
       "      <td>13300</td>\n",
       "      <td>0.120083</td>\n",
       "      <td>0.170530</td>\n",
       "      <td>0.709387</td>\n",
       "      <td>7/20/16</td>\n",
       "      <td>West</td>\n",
       "      <td>txt/WLA07-20-16audio_4DIR-2015-1282-DRB.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5 ZA-2014-4444-CD</td>\n",
       "      <td>ENV-2014-4445-MND</td>\n",
       "      <td>[(David, Wintrow)]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11003</td>\n",
       "      <td>5507</td>\n",
       "      <td>0.074101</td>\n",
       "      <td>0.230951</td>\n",
       "      <td>0.694947</td>\n",
       "      <td>7/20/16</td>\n",
       "      <td>West</td>\n",
       "      <td>txt/WLA07-20-16audio_5ZA-2014-4444-CDP.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6 PubCo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>580</td>\n",
       "      <td>301</td>\n",
       "      <td>0.555880</td>\n",
       "      <td>0.273227</td>\n",
       "      <td>0.170893</td>\n",
       "      <td>7/20/16</td>\n",
       "      <td>West</td>\n",
       "      <td>txt/WLA07-20-16audio_6PubCom.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               case_name               CEQA  \\\n",
       "0                1 DirRp                NaN   \n",
       "1               2 CommBu                NaN   \n",
       "2                   3 NC                NaN   \n",
       "3      4 VTT-74301+PubCo   ENV-2016-1898-CE   \n",
       "4       01DirectorsRepor                NaN   \n",
       "5    02CommissionBusines                NaN   \n",
       "6   03PublicCommentPerio                NaN   \n",
       "7           04CPC08-2142                NaN   \n",
       "8           05CPC12-1504   ENV-2012-1505-CE   \n",
       "9                1 DepRp                NaN   \n",
       "10              2 CommBu                NaN   \n",
       "11                  3 NC                NaN   \n",
       "12    4 DIR-2015-1282-DR   ENV-2015-1283-CE   \n",
       "13     5 ZA-2014-4444-CD  ENV-2014-4445-MND   \n",
       "14               6 PubCo                NaN   \n",
       "\n",
       "                                                names  names_count  \\\n",
       "0                                                  []            0   \n",
       "1                                                  []            0   \n",
       "2                                                  []            0   \n",
       "3                                                  []            0   \n",
       "4                                    [(Bill, Rochen)]            1   \n",
       "5                                                  []            0   \n",
       "6                                 [(Armando, Herman)]            1   \n",
       "7   [(Rigoberto, Urtado), (Anna, C), (Isabel, Roja...           24   \n",
       "8   [(George, U), (King, Chung), (Tari, Statelyn),...           20   \n",
       "9                                  [(Harden, Carter)]            1   \n",
       "10                                  [(Larry, Larson)]            1   \n",
       "11                                                 []            0   \n",
       "12                                 [(Harden, Carter)]            1   \n",
       "13                                 [(David, Wintrow)]            1   \n",
       "14                                                 []            0   \n",
       "\n",
       "    parking_mentions  affordability_mentions  community_mentions  num_words  \\\n",
       "0                  0                       0                   0        305   \n",
       "1                  0                       0                   0        342   \n",
       "2                  0                       0                   0         39   \n",
       "3                  0                       0                   0          0   \n",
       "4                  0                       0                   3       2739   \n",
       "5                  5                       0                   1       4270   \n",
       "6                  0                       0                   0        390   \n",
       "7                  0                       0                   1      28822   \n",
       "8                  0                       2                   7      16639   \n",
       "9                  0                       1                   0       1402   \n",
       "10                 0                       0                   2       1940   \n",
       "11                 0                       0                   1         84   \n",
       "12                 2                       0                   4      26434   \n",
       "13                 0                       0                   1      11003   \n",
       "14                 0                       1                   1        580   \n",
       "\n",
       "    num_nonstopgap_words  sentiment_pos  sentiment_neg  sentiment_neutral  \\\n",
       "0                    178       0.433737       0.023680           0.542582   \n",
       "1                    187       0.195975       0.032334           0.771691   \n",
       "2                     21       0.180984       0.064153           0.754864   \n",
       "3                      0       0.270926       0.058704           0.670370   \n",
       "4                   1356       0.341688       0.038798           0.619515   \n",
       "5                   2106       0.337581       0.077420           0.584999   \n",
       "6                    208       0.445862       0.013924           0.540214   \n",
       "7                  14536       0.194725       0.166172           0.639103   \n",
       "8                   8698       0.233360       0.172151           0.594489   \n",
       "9                    714       0.296306       0.028725           0.674969   \n",
       "10                   977       0.283531       0.086860           0.629609   \n",
       "11                    41       0.047930       0.012037           0.940033   \n",
       "12                 13300       0.120083       0.170530           0.709387   \n",
       "13                  5507       0.074101       0.230951           0.694947   \n",
       "14                   301       0.555880       0.273227           0.170893   \n",
       "\n",
       "       date  area                                  txt_file_name  \n",
       "0   1/25/17  East                txt/01-25-2017audio_1DirRpt.txt  \n",
       "1   1/25/17  East               txt/01-25-2017audio_2CommBus.txt  \n",
       "2   1/25/17  East                   txt/01-25-2017audio_3NCP.txt  \n",
       "3   1/25/17  East      txt/01-25-2017audio_4VTT-74301+PubCom.txt  \n",
       "4   7/12/12   CPC      txt/07-12-2012audio_01DirectorsReport.txt  \n",
       "5   7/12/12   CPC   txt/07-12-2012audio_02CommissionBusiness.txt  \n",
       "6   7/12/12   CPC  txt/07-12-2012audio_03PublicCommentPeriod.txt  \n",
       "7   7/12/12   CPC          txt/07-12-2012audio_04CPC08-2142f.txt  \n",
       "8   7/12/12   CPC          txt/07-12-2012audio_05CPC12-1504c.txt  \n",
       "9   7/20/16  West               txt/WLA07-20-16audio_1DepRpt.txt  \n",
       "10  7/20/16  West              txt/WLA07-20-16audio_2CommBus.txt  \n",
       "11  7/20/16  West                  txt/WLA07-20-16audio_3NCP.txt  \n",
       "12  7/20/16  West    txt/WLA07-20-16audio_4DIR-2015-1282-DRB.txt  \n",
       "13  7/20/16  West     txt/WLA07-20-16audio_5ZA-2014-4444-CDP.txt  \n",
       "14  7/20/16  West               txt/WLA07-20-16audio_6PubCom.txt  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_file_name</th>\n",
       "      <th>case_name</th>\n",
       "      <th>audio_file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-25-2017audio</td>\n",
       "      <td>1 DirRp</td>\n",
       "      <td>[01-25-2017audio_1 DirRpt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-25-2017audio</td>\n",
       "      <td>2 CommBu</td>\n",
       "      <td>[01-25-2017audio_2 CommBus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-25-2017audio</td>\n",
       "      <td>3 NC</td>\n",
       "      <td>[01-25-2017audio_3 NCP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-25-2017audio</td>\n",
       "      <td>4 VTT-74301+PubCo</td>\n",
       "      <td>[01-25-2017audio_4 VTT-74301+PubCom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07-12-2012audio</td>\n",
       "      <td>01DirectorsRepor</td>\n",
       "      <td>[07-12-2012audio_01DirectorsReport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>07-12-2012audio</td>\n",
       "      <td>02CommissionBusines</td>\n",
       "      <td>[07-12-2012audio_02CommissionBusiness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>07-12-2012audio</td>\n",
       "      <td>03PublicCommentPerio</td>\n",
       "      <td>[07-12-2012audio_03PublicCommentPeriod]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>07-12-2012audio</td>\n",
       "      <td>04CPC08-2142</td>\n",
       "      <td>[07-12-2012audio_04CPC08-2142a, 07-12-2012audi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>07-12-2012audio</td>\n",
       "      <td>05CPC12-1504</td>\n",
       "      <td>[07-12-2012audio_05CPC12-1504a, 07-12-2012audi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WLA 07-20-16audio</td>\n",
       "      <td>1 DepRp</td>\n",
       "      <td>[WLA 07-20-16audio_1 DepRpt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WLA 07-20-16audio</td>\n",
       "      <td>2 CommBu</td>\n",
       "      <td>[WLA 07-20-16audio_2 CommBus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WLA 07-20-16audio</td>\n",
       "      <td>3 NC</td>\n",
       "      <td>[WLA 07-20-16audio_3 NCP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WLA 07-20-16audio</td>\n",
       "      <td>4 DIR-2015-1282-DR</td>\n",
       "      <td>[WLA 07-20-16audio_4 DIR-2015-1282-DRB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WLA 07-20-16audio</td>\n",
       "      <td>5 ZA-2014-4444-CD</td>\n",
       "      <td>[WLA 07-20-16audio_5 ZA-2014-4444-CDP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>WLA 07-20-16audio</td>\n",
       "      <td>6 PubCo</td>\n",
       "      <td>[WLA 07-20-16audio_6 PubCom]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      clean_file_name             case_name  \\\n",
       "0     01-25-2017audio               1 DirRp   \n",
       "1     01-25-2017audio              2 CommBu   \n",
       "2     01-25-2017audio                  3 NC   \n",
       "3     01-25-2017audio     4 VTT-74301+PubCo   \n",
       "4     07-12-2012audio      01DirectorsRepor   \n",
       "5     07-12-2012audio   02CommissionBusines   \n",
       "6     07-12-2012audio  03PublicCommentPerio   \n",
       "7     07-12-2012audio          04CPC08-2142   \n",
       "8     07-12-2012audio          05CPC12-1504   \n",
       "9   WLA 07-20-16audio               1 DepRp   \n",
       "10  WLA 07-20-16audio              2 CommBu   \n",
       "11  WLA 07-20-16audio                  3 NC   \n",
       "12  WLA 07-20-16audio    4 DIR-2015-1282-DR   \n",
       "13  WLA 07-20-16audio     5 ZA-2014-4444-CD   \n",
       "14  WLA 07-20-16audio               6 PubCo   \n",
       "\n",
       "                                      audio_file_name  \n",
       "0                          [01-25-2017audio_1 DirRpt]  \n",
       "1                         [01-25-2017audio_2 CommBus]  \n",
       "2                             [01-25-2017audio_3 NCP]  \n",
       "3                [01-25-2017audio_4 VTT-74301+PubCom]  \n",
       "4                 [07-12-2012audio_01DirectorsReport]  \n",
       "5              [07-12-2012audio_02CommissionBusiness]  \n",
       "6             [07-12-2012audio_03PublicCommentPeriod]  \n",
       "7   [07-12-2012audio_04CPC08-2142a, 07-12-2012audi...  \n",
       "8   [07-12-2012audio_05CPC12-1504a, 07-12-2012audi...  \n",
       "9                        [WLA 07-20-16audio_1 DepRpt]  \n",
       "10                      [WLA 07-20-16audio_2 CommBus]  \n",
       "11                          [WLA 07-20-16audio_3 NCP]  \n",
       "12            [WLA 07-20-16audio_4 DIR-2015-1282-DRB]  \n",
       "13             [WLA 07-20-16audio_5 ZA-2014-4444-CDP]  \n",
       "14                       [WLA 07-20-16audio_6 PubCom]  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapsed_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
