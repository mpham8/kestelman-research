{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.spatial.distance import cdist\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_name</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_clean</th>\n",
       "      <th>topic_mentioned</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prob_score_neg</th>\n",
       "      <th>prob_score_neutral</th>\n",
       "      <th>prob_score_pos</th>\n",
       "      <th>has_parking</th>\n",
       "      <th>has_econactivity</th>\n",
       "      <th>...</th>\n",
       "      <th>sent_voice_mentioned</th>\n",
       "      <th>sentpol_voice_mentioned</th>\n",
       "      <th>prob_pos_voice_mentioned</th>\n",
       "      <th>prob_neg_voice_mentioned</th>\n",
       "      <th>positive_voice_mentioned</th>\n",
       "      <th>negative_voice_mentioned</th>\n",
       "      <th>num_voice_mentioned</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>sentence_lower</th>\n",
       "      <th>count_my_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09-12-2017audio_6ZA-2017-210-CU-1A</td>\n",
       "      <td>My name is Jerry Newman.</td>\n",
       "      <td>My name is Jerry Newman.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>my name is jerry newman.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09-12-2017audio_6ZA-2017-210-CU-1A</td>\n",
       "      <td>Thank you, President Chunkham, members of the ...</td>\n",
       "      <td>Thank you, President Chunkham, members of the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>thank you, president chunkham, members of the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09-12-2017audio_6ZA-2017-210-CU-1A</td>\n",
       "      <td>The question that is asked and that was asked ...</td>\n",
       "      <td>The question that is asked and that was asked ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>the question that is asked and that was asked ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09-12-2017audio_6ZA-2017-210-CU-1A</td>\n",
       "      <td>And I think Mr. Chang made an adequate descrip...</td>\n",
       "      <td>And I think Mr. Chang made an adequate descrip...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>and i think mr. chang made an adequate descrip...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09-12-2017audio_6ZA-2017-210-CU-1A</td>\n",
       "      <td>We started thinking through a business plan an...</td>\n",
       "      <td>We started thinking through a business plan an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>we started thinking through a business plan an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             new_name  \\\n",
       "0  09-12-2017audio_6ZA-2017-210-CU-1A   \n",
       "1  09-12-2017audio_6ZA-2017-210-CU-1A   \n",
       "2  09-12-2017audio_6ZA-2017-210-CU-1A   \n",
       "3  09-12-2017audio_6ZA-2017-210-CU-1A   \n",
       "4  09-12-2017audio_6ZA-2017-210-CU-1A   \n",
       "\n",
       "                                            sentence  \\\n",
       "0                           My name is Jerry Newman.   \n",
       "1  Thank you, President Chunkham, members of the ...   \n",
       "2  The question that is asked and that was asked ...   \n",
       "3  And I think Mr. Chang made an adequate descrip...   \n",
       "4  We started thinking through a business plan an...   \n",
       "\n",
       "                                      sentence_clean topic_mentioned  \\\n",
       "0                           My name is Jerry Newman.             NaN   \n",
       "1  Thank you, President Chunkham, members of the ...             NaN   \n",
       "2  The question that is asked and that was asked ...             NaN   \n",
       "3  And I think Mr. Chang made an adequate descrip...             NaN   \n",
       "4  We started thinking through a business plan an...             NaN   \n",
       "\n",
       "   sentiment  prob_score_neg  prob_score_neutral  prob_score_pos  has_parking  \\\n",
       "0        NaN             NaN                 NaN             NaN            0   \n",
       "1        NaN             NaN                 NaN             NaN            0   \n",
       "2        NaN             NaN                 NaN             NaN            0   \n",
       "3        NaN             NaN                 NaN             NaN            0   \n",
       "4        NaN             NaN                 NaN             NaN            0   \n",
       "\n",
       "   has_econactivity  ...  sent_voice_mentioned  sentpol_voice_mentioned  \\\n",
       "0                 0  ...                   NaN                      NaN   \n",
       "1                 0  ...                   NaN                      NaN   \n",
       "2                 0  ...                   NaN                      NaN   \n",
       "3                 0  ...                   NaN                      NaN   \n",
       "4                 0  ...                   NaN                      NaN   \n",
       "\n",
       "   prob_pos_voice_mentioned  prob_neg_voice_mentioned  \\\n",
       "0                       NaN                       NaN   \n",
       "1                       NaN                       NaN   \n",
       "2                       NaN                       NaN   \n",
       "3                       NaN                       NaN   \n",
       "4                       NaN                       NaN   \n",
       "\n",
       "   positive_voice_mentioned  negative_voice_mentioned  num_voice_mentioned  \\\n",
       "0                       NaN                       NaN                    0   \n",
       "1                       NaN                       NaN                    0   \n",
       "2                       NaN                       NaN                    0   \n",
       "3                       NaN                       NaN                    0   \n",
       "4                       NaN                       NaN                    0   \n",
       "\n",
       "   num_sentences                                     sentence_lower  \\\n",
       "0              1                           my name is jerry newman.   \n",
       "1              1  thank you, president chunkham, members of the ...   \n",
       "2              1  the question that is asked and that was asked ...   \n",
       "3              1  and i think mr. chang made an adequate descrip...   \n",
       "4              1  we started thinking through a business plan an...   \n",
       "\n",
       "   count_my_name  \n",
       "0              1  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_text_onlyspeaker_df = pd.read_csv(\"cases_text_onlyspeaker.csv\")\n",
    "cases_text_onlyspeaker_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(column):\n",
    "  rows = cases_text_onlyspeaker_df[cases_text_onlyspeaker_df[column] == 1]\n",
    "  all_sentences = rows[\"sentence\"].tolist()\n",
    "  \n",
    "  return model.encode(all_sentences), all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "#cosine similarity\n",
    "parking_embeddings, parking_sentences = get_embeddings('has_parking')\n",
    "\n",
    "# for i in range(len(parking_embeddings)):\n",
    "  \n",
    "# a = util.pytorch_cos_sim(embedding_1, embedding_2)\n",
    "\n",
    "print(parking_embeddings[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Lacking space for parking in this current parking lot.\",\n",
    "    \"We have no parking in this building.\",\n",
    "    \"However, the first time you visit the restaurant, if you drive up and find parking in that neighborhood in Venice, good luck.\",\n",
    "    \"We are very concerned about enough parking for our carseverybody to keep it off the already loaded with cars.\",\n",
    "    \"And if youre a senator, then theres already more pressure on the parking in the neighborhood and keep in mind the other factor that theres absolutely no parking on Sunday.\",\n",
    "    \"This is their plan to put parking and back of our building, leaving us with absolutely no parkingparking whatsoever and weve shared this parking for about 30 Ive been in the business for 31 years Ive been in that community for 31 years Thank you And is that all that I have one minute?\",\n",
    "    \"And there is no parking.\",\n",
    "    \"However, the first time you visit the restaurant, if you drive up and find parking in that neighborhood in Venice, good luck.\",\n",
    "    \"So is there going to be, I think I, is there going to be any offside parking thats going to be designated for some of the people that work there?\",\n",
    "    \"Again, that is a reason for the additional parking which is required in this case, which I previously explained.\",\n",
    "    \"So Im strongly recommending that the residents create another parking district so we can have parking spaces in front of our homes because these on-site off-site parking that the restaurant applicants are suggestingwill not suffice.\",\n",
    "    \"The neighborhood is already dealing with a two-and-a-half 25 capacity bar set to open this year with with very little to no parking and whose hours of operation would be from 11 amto 2 am.\",\n",
    "    \"Theres not enough parking for guests and And there was one suggestion of the home on the site be up for harvesting.\"\n",
    "]\n",
    "example_sentence_embedding = model.encode(sentences)\n",
    "\n",
    "counter_sentences = [\n",
    "    \"Furthermore, the Coastal Commission has denied us permit parking in our neighborhood.\",\n",
    "    \"The certificate occupancy was issued condition upon the the recreation room being provided in the same way that a certificate occupancy is our issue condition upon parking being provided.\",\n",
    "    \"They are asking deviation from the required parking for the fifth dwelling unit.\",\n",
    "    \"Very clearly and as I stated earlier when looking at certificate occupancy and there is something that stated in a certificate occupancy that has to be provided and I relate to you when parking has to be provided.\",\n",
    "    \"And we will try to make the, we will be adding the bike, the biking racks to help alleviate that extra parking.\",\n",
    "    \"So what Dana is saying is, can we maybe amend any existing surface parking?\",\n",
    "    \"But it is, it was built originally to allow parking there, and again, its interlocking favors.\",\n",
    "    \"Thank youthat if they could have two security guards instead of three as requested in here in the parking lot versus in the restaurant, what would would that be adequate?\",\n",
    "    \"Chains in the parking lot, their metal chains on plastic ballads.\",\n",
    "    \"Many of the children walk to the school, they have to pass these parking lots, they have to pass these commercial zoned properties where cars are going in and out all the time.\",\n",
    "    \"One of the things that attracted me to that space and to the bank building that is across the street from the Masonic lodge is the luxury of parking at night.\",\n",
    "    \"Wheres the ADA parking spot, parking spot, plural or singular?\"\n",
    "]\n",
    "\n",
    "counter_sentences_embeddings = model.encode(counter_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sentence = [\"lack parking\", \"no parking\", \"there is not enough parking\", \"needs to be more parking\"]\n",
    "\n",
    "topic_sentence_embedding = model.encode(topic_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lack parking:  0.54 avr, [0.74, 0.65, 0.34, 0.55, 0.5, 0.51, 0.72, 0.34, 0.47, 0.59, 0.48, 0.51, 0.58]\n",
      "no parking:  0.54 avr, [0.64, 0.79, 0.41, 0.48, 0.48, 0.51, 0.83, 0.41, 0.47, 0.49, 0.47, 0.5, 0.54]\n",
      "there is not enough parking:  0.54 avr, [0.76, 0.63, 0.34, 0.57, 0.48, 0.51, 0.72, 0.34, 0.47, 0.63, 0.49, 0.49, 0.58]\n",
      "needs to be more parking:  0.53 avr, [0.75, 0.48, 0.36, 0.6, 0.54, 0.54, 0.59, 0.36, 0.51, 0.59, 0.55, 0.52, 0.55]\n",
      "\n",
      " Counter-sentences:\n",
      "lack parking:  0.42 avr, [0.37, 0.35, 0.49, 0.4, 0.48, 0.45, 0.44, 0.34, 0.31, 0.48, 0.39, 0.51]\n",
      "no parking:  0.39 avr, [0.43, 0.33, 0.39, 0.41, 0.45, 0.46, 0.41, 0.28, 0.29, 0.41, 0.37, 0.5]\n",
      "there is not enough parking:  0.41 avr, [0.38, 0.38, 0.5, 0.39, 0.44, 0.45, 0.46, 0.35, 0.23, 0.45, 0.34, 0.5]\n",
      "needs to be more parking:  0.45 avr, [0.35, 0.36, 0.52, 0.41, 0.61, 0.55, 0.49, 0.43, 0.3, 0.5, 0.41, 0.51]\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(topic_sentence_embedding)):\n",
    "  topic_scores_ls = []\n",
    "  for i in range(len(example_sentence_embedding)):\n",
    "    cos_similarity = util.pytorch_cos_sim(topic_sentence_embedding[j], example_sentence_embedding[i])\n",
    "    cos_similarity_value = round(cos_similarity.item(), 2)\n",
    "    topic_scores_ls.append(cos_similarity_value)\n",
    "\n",
    "  counter_avg = sum(topic_scores_ls) / len(topic_scores_ls)\n",
    "\n",
    "  print(f\"{topic_sentence[j]}:  {counter_avg:.2f} avr, {topic_scores_ls}\")\n",
    "\n",
    "print(\"\\n Counter-sentences:\")\n",
    "for j in range(len(topic_sentence_embedding)):\n",
    "  topic_scores_ls = []\n",
    "  for i in range(len(counter_sentences_embeddings)):\n",
    "    cos_similarity = util.pytorch_cos_sim(topic_sentence_embedding[j], counter_sentences_embeddings[i])\n",
    "    cos_similarity_value = round(cos_similarity.item(), 2)\n",
    "    topic_scores_ls.append(cos_similarity_value)\n",
    "\n",
    "  counter_avg = sum(topic_scores_ls) / len(topic_scores_ls)\n",
    "\n",
    "  print(f\"{topic_sentence[j]}:  {counter_avg:.2f} avr, {topic_scores_ls}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_sentences(topic_sentences, sentence_embeddings, sentences, threshold=0.6):\n",
    "    similar_sentences = []\n",
    "    not_similar_sentences = []\n",
    "    topic_sentence_embedding = model.encode(topic_sentences)\n",
    "    \n",
    "    for i, sentence_embedding in enumerate(sentence_embeddings):\n",
    "        cos_similarity_ls = [\n",
    "            util.pytorch_cos_sim(sentence_embedding, topic_embedding).item()\n",
    "            for topic_embedding in topic_sentence_embedding\n",
    "        ]\n",
    "        \n",
    "        if any(val > threshold for val in cos_similarity_ls):\n",
    "            similar_sentences.append(sentences[i])\n",
    "        else:\n",
    "            not_similar_sentences.append(sentences[i])\n",
    "    \n",
    "    return similar_sentences, not_similar_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample of 10 similar sentences:\n",
      "He basically submitted an application and said he needed no additional parking.\n",
      "So that might be an area that youd be able to utilize and try and reduce that number of people that use the parking even though there may be where large trucks for production are using the parking and theres not actually those vehicles miles traveled in the area, but it might help offset that number youre kind of looking at.\n",
      "I just want to kind of recap what we are parking in that parking lot.\n",
      "Okay, so your parking is none of it is sub-training.\n",
      "Theres parking.\n",
      "So theyre going to be parking in our neighborhood.\n",
      "Okayand somehow designating where the parking entrance is.\n",
      "I own a small, I run a small corner in the market and theres been always been a big issue with the parking and the create town is getting more and more crowded and Im glad this projects coming in its gonna provide Im a hundred of parking there, especially with bicycle parking.\n",
      "All right comments are just generally as always about the parking.\n",
      "If we go to build this in our property, you have have issue of parking.\n",
      "\n",
      "Total number of similar sentences: 2735\n",
      "\n",
      "Random sample of 10 not similar sentences:\n",
      "If you have a massive building, and this is almost 400,000 square feet, including the parking area, and you put it on an east-west axis, youre gonna block view sheds for thousands of people.\n",
      "The absolute failure of traffic control in and out of the Bevmo parking lots by trucks and carswho are customers, resulting in horns blowing and loud shouting of other drivers of cars in the alley being blockedme a woman of 91 years to go out my gate because there was such a complete standstill to help a woman navigate out and the cars and the carsthe bedmode parking lot create congestion going in and out.\n",
      "Im not sure how it would work out but theres a request for the Zoning Administrators Adjustment to permit one uncovered parking space within the required front yard.\n",
      "I mean, the noisy sound, but the plan that they have, the way they drop off and pick up doing their own musicthe Parking lot, but theyre going to make a one-way street out of the alley itself is an exit.\n",
      "That FAR is Ms. Lamb just pointed out with 4.2 to 1 and the parking that was in that project basically met code it didnt provide any additional parking and Also one other element that was critical to that original design is that there was a bill board that was on the south elevation of the design.\n",
      "Im going on testimony that they were looking at the parking and the massing.\n",
      "So, you know, I dont know what the timing was just unique, but as an owner, when I first signed up and bought 10 years ago, I was under the impressionthere was visitor parking pretty much all the time and now its quite difficult to park if at all.\n",
      "Compared to what would have resulted without the bonus, there will be two unitsto four more extra cars, roving the streets, looking for parking every night.\n",
      "The first is to clarify that from my perspective as a resident of the units, there are four underground commercial floors of parking separately accessed and theres about 12 floors of residential parking.\n",
      "Im assuming, but again, I think that, based on the building permit, that the parking on the premises should be allocated to the commercial use, though.\n",
      "\n",
      "Total number of not similar sentences: 5187\n"
     ]
    }
   ],
   "source": [
    "topic_sentence = [\"lack parking\", \"no parking\", \"there is not enough parking\", \"needs to be more parking\"]\n",
    "\n",
    "threshold = 0.55\n",
    "similar_sentences, not_similar_sentences = find_similar_sentences(topic_sentence, parking_embeddings, parking_sentences, threshold)\n",
    "\n",
    "\n",
    "print(\"Random sample of 10 similar sentences:\")\n",
    "for sentence in random.sample(similar_sentences, min(10, len(similar_sentences))):\n",
    "    print(sentence)\n",
    "print(f\"\\nTotal number of similar sentences: {len(similar_sentences)}\")\n",
    "\n",
    "print(\"\\nRandom sample of 10 not similar sentences:\")\n",
    "for sentence in random.sample(not_similar_sentences, min(10, len(not_similar_sentences))):\n",
    "    print(sentence)\n",
    "print(f\"\\nTotal number of not similar sentences: {len(not_similar_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#could implement exclusivity. 4 topic, match to most similar one if each above threshold\n",
    "#add accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
