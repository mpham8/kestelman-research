{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "from transformers import pipeline as transcribe_pipeline\n",
    "import torchaudio\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "import torch\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import pandas as pd\n",
    "\n",
    "from config import HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /Users/mpham/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pyannote pipeline\n",
      "loading whisper model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting to .wav file\n",
      "performing diarization\n"
     ]
    }
   ],
   "source": [
    "# Initialize pyannote pipeline for speaker diarization\n",
    "print(\"loading pyannote pipeline\")\n",
    "diarization_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\")\n",
    "\n",
    "# Initialize Whisper model for ASR (automatic speech recognition)\n",
    "print(\"loading whisper model\")\n",
    "whisper_model = transcribe_pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base\")\n",
    "\n",
    "# Path to your audio file\n",
    "# Convert MP3 to WAV\n",
    "print(\"converting to .wav file\")\n",
    "mp3_file = \"07_CPC_2022_6189.mp3\"\n",
    "wav_file = mp3_file.replace(\".mp3\", \".wav\")\n",
    "audio = AudioSegment.from_mp3(mp3_file)\n",
    "audio.export(wav_file, format=\"wav\")\n",
    "\n",
    "# Use the WAV file for processing\n",
    "audio_file = wav_file\n",
    "\n",
    "# Perform diarization\n",
    "print(\"performing diarization\")\n",
    "diarization = diarization_pipeline(audio_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "# model_id = \"openai/whisper-large-v3\"\n",
    "model_id = \"openai/whisper-base\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading audio file\n",
      "processing segments\n",
      "Speaker 39:  Good morning commissioners. I'm Kevin Golden, city planner with the Expedited Processing Section and what we have before you is the Mission Road Project.\n",
      "Speaker 35:  Morning commissioners, Heather Bliemers, the Department of City Planning. As mentioned, we just wanted to get this in the record before your consideration of the project.\n",
      "Speaker 39:  Thank you.\n",
      "Speaker 04:  Thank you so much. We will now hear from the applicant. Please approach the podium. And please state your name for the record and speak directly into the microphone. We have Shay Yadden from Lincoln Park Holdings. And I believe Jesse Harris is here.\n",
      "Speaker 12:  That's correct.\n",
      "Speaker 04:  Good morning.\n",
      "Speaker 12:  Good morning.\n",
      "Speaker 04:  How many minutes will you need?\n",
      "Speaker 12:  I'm going to request 20 minutes. Please excuse a exceptionally long presentation, but there's a lot that we feel that we want to address with this project. I'll try to be quicker than that if possible.\n",
      "Speaker 04:  that is possible. Okay.\n",
      "Speaker 00:  you\n",
      "Speaker 12:  All right. All right. And then we have questions. We'll certainly follow up. All right. All right.\n",
      "Speaker 04:  You're coming up in and on the clock.\n",
      "Speaker 32:  Thank you for joining us. Thank you.\n",
      "Speaker 04:  All right, the time goes quickly. Oh, that's your one minute. Appreciate it. Thank you. The next speaker card I have is for Rio. Oh, OXOS? Oh, HOS?\n",
      "Speaker 31:  That's your\n",
      "Speaker 32:  in the problem.\n",
      "Speaker 04:  Good morning.\n",
      "Speaker 23:  you\n",
      "Speaker 04:  Thank you.\n",
      "Speaker 37:  Thank you. Denise Charles for the record. We currently have 22 hands raised. First one, Juan Luna. You are now able to unmute. Please proceed.\n",
      "Speaker 14:  Yes, that's what you're giving me.\n",
      "Speaker 37:  Yes?\n",
      "Speaker 14:  Okay. Um, yes, my name is Juan Ruehna. I'm a member of the Southwest Palm State Regional Council of Partners. I work and recreate in the vicinity of the project. I believe that I will be impacted by the environmental impacts of the project.\n",
      "Speaker 37:  Thank you, that is your time.\n",
      "Speaker 14:  time.\n",
      "Speaker 37:  Bent Accord, you are now able to unmute please proceed.\n",
      "Speaker 11:  Good morning. This is a privilege to speak for the City Planning Commission.\n",
      "Speaker 37:  Thank you. That is your time.\n",
      "Speaker 11:  you\n",
      "Speaker 37:  you\n",
      "Speaker 11:  We are happy.\n",
      "Speaker 37:  L. J. Monitor.\n",
      "Speaker 19:  I'm a newbie, I'm a regular guy, I'm a real, I live on 2528, I'm a new department number 8.\n",
      "Speaker 29:  you\n",
      "Speaker 19:  you\n",
      "Speaker 29:  And I am a resident here. I also have a long life where it should trip with the community.\n",
      "Speaker 37:  Thank you. That is your time.\n",
      "Speaker 29:  you\n",
      "Speaker 37:  Silva, you are not able to immune, please proceed.\n",
      "Speaker 17:  Hello? Can you hear me?\n",
      "Speaker 37:  you\n",
      "Speaker 04:  Yes, go ahead.\n",
      "Speaker 17:  Still the Blackstone retired certified Arbor.\n",
      "Speaker 37:  Thank you. That is your time.\n",
      "Speaker 15:  Hi, good morning. My name is Armando. I live in this house. I live on that street on the city of Hattane. I'm following up with the issue of this mostly building. If it would be on the center of the housing, that'd be pretty. Before I give Miss Econ, it's really a slap in the face. All that's going to do is to activate the location. This is an area very, very bad. Yeah.\n",
      "Speaker 37:  Thank you.\n",
      "Speaker 16:  Yeah, you're cute.\n",
      "Speaker 37:  Thank you. That is your time.\n",
      "Speaker 05:  Hello, my name is Amy Leber, I'm a resident of CD14 and I'm the executive director of Motivating Our Students for Experience I'm mentoring in College Access Program, which is a wild girl, she looks at the students in Lincoln Heights, she works with students in Lincoln Heights.\n",
      "Speaker 37:  you\n",
      "Speaker 05:  you\n",
      "Speaker 37:  Thank you.\n",
      "Speaker 10:  Hi, I'd like to say a quick thing about public comment. I've always been to minutes and all of a sudden it's one minute. But when you hear about this meeting, there's a region that you can be dealing with by the way through Apple for State employees that you're just meeting people. I also want to say that our event at State employees is not really quite about the same and our statement, more any of the state is that right the last hearing or any people't have a golden sample port which seems very biased in the Middle East. I want to note that I have heard this exact presentation I'd have developed very, very biased. Not one thing has changed down to the exact same or the exact same that used. I want to remind everyone on this board about your ruling for the luxury development of Avenue 34 in the very same exact neighborhood with very high top seven levels of soil.\n",
      "Speaker 37:  Thank you, that is your time. Arturo Rojas, you are now able to unmute, please proceed.\n",
      "Speaker 10:  you\n",
      "Speaker 13:  We are supporting an honorable position for this project. The assembly for the project, and the meeting itself, and the major council has a month. And he hears the major council, the major council, saying that the incentive and saying that the proposal is the project. I think the action is in the, in the, in the, in the, and the, in Dancing in the People's Rights and be free to follow the rightist partner in the people's rights. We can welcome that to explore the ideas of thinking in a very much humble code from the public.\n",
      "Speaker 37:  Thank you, Nicole. You are not able to unmute. Please proceed.\n",
      "Speaker 29:  Hi, my name is Paul Corona. I am a resident of Lincoln High School of Duke over 20 years. I'm 21 years old and I am a strong opposition of this project. And this is my first time listening to a new year. I wanted to look at the agenda. I am a lot of these are waiver of development, seem like exceptions.\n",
      "Speaker 37:  Thank you Nicole, that is your time.\n",
      "Speaker 29:  Thank you.\n",
      "Speaker 37:  Cat Jones, you are now able to unmute please proceed.\n",
      "Speaker 08:  Hi, I'm a pilot in the pilot's pilot. I've been working in the pilot's pilot for over six years and I've been working for over six years.\n",
      "Speaker 31:  you\n",
      "Speaker 08:  What is your name?\n",
      "Speaker 37:  Thank you. That is your time.\n",
      "Speaker 29:  Hi, my name is Julie from Sonskullis and I'm a resident of Lique Heights. All the communities I have built up in and have been having this fight at the heart of the Highland Park in the New York Times. And this will be here in Lique Heights, which I now call my community.\n",
      "Speaker 37:  Thank you. That is your time.\n",
      "Speaker 31:  you\n",
      "Speaker 37:  you\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker 19: 嗨 哎呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀呀\n",
      "Speaker 29:  Thank you.\n",
      "Speaker 19:  you\n",
      "Speaker 29:  I want to...\n",
      "Speaker 19:  and\n",
      "Speaker 29:  Thank you, I'm such a...\n",
      "Speaker 19:  you\n",
      "Speaker 29:  you\n",
      "Speaker 19:  you\n",
      "Speaker 29:  Actually, I was eligible to decide this.\n",
      "Speaker 19:  you\n",
      "Speaker 29:  very small apocalyptic in LA to those popular splatters and species.\n",
      "Speaker 37:  Thank you, that is your time.\n",
      "Speaker 09:  Yes, first of all, I have a light on the lens and it has some very active.\n",
      "Speaker 31:  MBC 뉴스 김\n",
      "Speaker 09:  Um\n",
      "Speaker 37:  Thank you. Sergio Garcia, you are not able to amuse. Please proceed.\n",
      "Speaker 07:  Oh, here you go.\n",
      "Speaker 37:  Thank you. That is your time.\n",
      "Speaker 24:  Hello, my name is Lina, I'm a Canadian.\n",
      "Speaker 19:  I'm sorry, I didn't ask you for it.\n",
      "Speaker 29:  Thank you.\n",
      "Speaker 19:  MBC 뉴스 김\n",
      "Speaker 29:  MBC 뉴스 김\n",
      "Speaker 37:  Thank you.\n",
      "Speaker 24:  Yes, the I remember.\n",
      "Speaker 19:  MBC 뉴스 김\n",
      "Speaker 24:  MBC 뉴스 김\n",
      "Speaker 31:  MBC 뉴스 김\n",
      "Speaker 37:  Thank you. That is your time.\n",
      "Speaker 24:  I'm seeing a guy on the same time, who's what he looks like.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker 31:  you\n",
      "Speaker 37:  Thank you. Thank you. That is your time.\n",
      "Speaker 30:  Thank you.\n",
      "Speaker 31:  you\n",
      "Speaker 30:  you\n",
      "Speaker 37:  Kim, you are not able to amuse, please proceed.\n",
      "Speaker 31:  MBC 뉴스 김\n",
      "Speaker 24:  MBC 뉴스 김\n",
      "Speaker 26:  you\n",
      "Speaker 24:  MBC 뉴스 김\n",
      "Speaker 26:  I'm sorry, I'm sorry.\n",
      "Speaker 00:  you\n",
      "Speaker 26:  have this level of work that has been very unhappy for us as a scientist for this project, because of new ideas and the core of our resilience that has been through different issues.\n",
      "Speaker 37:  Thank you.\n",
      "Speaker 19:  Hi, my name is Cindy Perez. I am a graduate from the State University of New Zealand. I'm a company, some of the third-graders. And I am calling to you, saying that I am it's true of post to this development. I am here to offer you to that institute exchange of Nalisida Extension, and I will be your open-ended online.\n",
      "Speaker 29:  I'm just going to be doing a best idea as well. I appreciate that you love me, and that the house that you love again.\n",
      "Speaker 22:  Thank you.\n",
      "Speaker 37:  Thank you. Dakhma, you are now able to unmute. Please proceed.\n",
      "Speaker 24:  Thank you.\n",
      "Speaker 37:  Thank you, that is your time.\n",
      "Speaker 24:  MBC 뉴스 김\n",
      "Speaker 37:  Camarillo, you are not able to amuse, please proceed.\n",
      "Speaker 21:  and the next project. I'm not allowed to try this in mass homoses and mass homoses, but the project is streamenously and only the 50% project that is being done is hardly misdemeanored.\n",
      "Speaker 37:  Thank you. That is your time.\n",
      "Speaker 28:  Here, baby, I'll jump in, and we'll see you on my back.\n",
      "Speaker 37:  Thank you. That is your time.\n",
      "Speaker 28:  Hi, my name is James Avera. I am the first therapist of the Funding Management and the Lincoln High School of Council. At our Funding Management meeting, we've already been having a seat against this project. We've heard from the community by the way we are the back to representatives. We are both a hand-by part community who represents it. They said multiple projects. We've already been having a seat against it. At the time, we've been having a seat. I'd like to thank our general board, you need their answers. We're constantly waiting for you. I said, most of these projects, we've already been having to be against it. I have a time to have this to look at our general board. You need their answers. We also need an agency board against this project.\n",
      "Speaker 37:  Snacky for the City of Lincoln Heights. You are now able to unmute. Please proceed.\n",
      "Speaker 29:  Yeah.\n",
      "Speaker 31:  you\n",
      "Speaker 29:  you\n",
      "Speaker 31:  you\n",
      "Speaker 37:  Thank you. That is your time. Samir Hassaba, you are now able to unmute. Please proceed.\n",
      "Speaker 19:  Bye, my name is Sandi.\n",
      "Speaker 29:  and you found three left in a mile from this development target.\n",
      "Speaker 22:  you\n",
      "Speaker 29:  So I have opportunities for you. I feel that you want to increase investment in policy and it got to stop.\n",
      "Speaker 37:  Thank you. That is your time.\n",
      "Speaker 29:  you\n",
      "Speaker 37:  On Ali, now you're in. It went to the mute. Please proceed.\n",
      "Speaker 30:  Thank you.\n",
      "Speaker 37:  Thank you.\n",
      "Speaker 30:  You're the one that got it?\n",
      "Speaker 29:  you\n",
      "Speaker 30:  you\n",
      "Speaker 29:  for this morning.\n",
      "Speaker 30:  I'm going to take them right now.\n",
      "Speaker 29:  to what's in it.\n",
      "Speaker 37:  Thank you. That is your time.\n",
      "Speaker 18:  you\n",
      "Speaker 37:  Thank you. Am I noel? You are not able to unmute. Please proceed.\n",
      "Speaker 06:  and that's good morning to you. See you later.\n",
      "Speaker 20:  you\n",
      "Speaker 37:  Thank you. That is your time.\n",
      "Speaker 20:  Thank you.\n",
      "Speaker 37:  You are now able to unmute. Please proceed.\n",
      "Speaker 28:  I oppose this project 100%.\n",
      "Speaker 37:  Thank you. That is your time. Perez, you are not able to amuse. Please proceed.\n",
      "Speaker 27:  on many different methods for health, disease, and over 30 years.\n",
      "Speaker 37:  Thank you. That is your time.\n",
      "Speaker 24:  That is your time.\n",
      "Speaker 27:  Thank you.\n",
      "Speaker 37:  Color 2052 you are now able to amuse please press star 6\n",
      "Speaker 29:  MBC 뉴스 김\n",
      "Speaker 37:  Thank you.\n",
      "Speaker 29:  you\n",
      "Speaker 37:  MBC 뉴스 김\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker 29:  Yes, many of the times we've been using this kind of thing that we've seen in the last minutes, some of the reasons we've been doing this, but I think it's a very, very, I think it's a very, very, very, I would say that the timing is great, so it's a very, very, very, very, very, very, very, very, very, very, very, very, very, very, very, that it's so kind of accurate.\n",
      "Speaker 25:  you\n",
      "Speaker 37:  Thank you, that is your time. Dahmah, you are not able to amuse, please proceed.\n",
      "Speaker 25:  you\n",
      "Speaker 29:  Thank you.\n",
      "Speaker 25:  Thank you.\n",
      "Speaker 29:  I don't know.\n",
      "Speaker 25:  I'm just trying to find out if I can hold in certain locations. So I did mine, and I did see them in a community.\n",
      "Speaker 29:  and the work council is an out of request of not to be seen as other folks work communities by enjoying the active and open color, a violent development that I'm not sure if I'm pleased. This project will perpetuate an environment of racism. Please, afford to be an inspirational equity after the student chose to come out early in the seat and deny all of the three sides through federal government. Just happy about the development with served your seat, not think this is human. If a person who actually is one of our dumb, a water system, how do you think human rights do you think we really need to be doing? This has been a happy development with the government. You have to think this is a new way. If a person were actually a born-of-all, a father of sister, how would you think that right? You would be willing to come, you could modify a very new or funny, a completely lost man's life, not see these values for a possible life. Thank you.\n",
      "Speaker 37:  Thank you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker 25:  I think you're saying right now, I'm not sure if that is going to say it. I'm making a kind of talk to the world, all the times, I've been thinking of the universe and say that, saying obviously, along with my neighbors, and so you make sure that I heard from the outside talk to you very many and talk to you guys about that. And I wanted to say, no, but I think I was saying, you're saying, talk to me about the universe, and then we'll see you in the next video.\n",
      "Speaker 37:  Thank you. Hugo Pacheco, you're not able to unmute. Please proceed.\n",
      "Speaker 15:  Thank you.\n",
      "Speaker 37:  Thank you. Community resilient. You're not able to unmute. Please proceed.\n",
      "Speaker 30:  Hi, thanks.\n",
      "Speaker 31:  MBC 뉴스 김\n",
      "Speaker 30:  I'm going to stay like knowledge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker 37:  Thank you. That was our last caller, Vice President Joe.\n",
      "Speaker 04:  Thank you. We have a couple of more speaker cards for in-person speakers here, so I'd like to call up. Kevin Scott.\n",
      "Speaker 33:  Hello, my name is Kevin Scott. I'm a resident of Northeast LA and I want to express my enthusiastic support for this project, which will add 184 units of housing, including 47 units affordable to very low-income renters.\n",
      "Speaker 04:  Thank you.\n",
      "Speaker 01:  Hi, my name is Anthony Daniel. I'm a self of 45 seconds because I don't want to be cut off. So I live in a low income subsidized housing program. And I was at one of the youth that all these people are talking about. Like, oh, they're just going to stay homeless. I have an issue with that because no. I sing with the trans course of Los Angeles as an openly trans activist. I have an issue with the fact that y'all really believe that this is all rumor based. I'm sorry if you live close to there, you should be in support of this because how dare you go ahead and be saying that we are just gonna dehumanize people so much that you're just like put all the homeless either on the street or in a random ass building. No. live close to there, you should be in support of this because how dare you go ahead and be saying that we are just going to dehumanize people so much that you're just like put all the homo-sealer on the street or in a random ass building. Now put them in a nice building, which is like the one that I live in and I thrive.\n",
      "Speaker 04:  Thank you.\n",
      "Speaker 36:  Thank you.\n",
      "Speaker 04:  address that so please go ahead.\n",
      "Speaker 36:  you\n",
      "Speaker 04:  Thank you for that clarification. So I believe we do not have any council members representative here today to speak.\n",
      "Speaker 36:  Thank you.\n",
      "Speaker 31:  you\n",
      "Speaker 00:  you\n",
      "Speaker 04:  Okay, so with that, I will close a public testimony now.\n",
      "Speaker 35:  Thank you, Commissioner. This is Heather Blamers, Department of City Planning. I'd like to go over a few things that I heard the public bring up, and I'm happy to answer additional questions at the end of my presentation. So there was concerns with the notification of the hearing. This hearing was noticed to all parties, including the 500-foot radius and interested parties, as part of that package. We do notice the neighborhood council, the council office, and like I said, 500 foot radius. So we are confident that the address, that the building application is listed, I believe two different sets of addresses. Those, that is the correct address of the project and 500 foot radius from that address was notified. Regarding CEQA, there were quite a bit of comments regarding CEQA. This did receive a class 32 as the environmental clearance for the project. I do want to state though that this is not just a simple exemption. We have over 200 pages of appendices to our document of technical studies. We have the air quality study, a noise study, traffic study, tree report. If there was a historic building on the site, we would have that too. So just want to confirm that there was a lot of effort and a lot of technical analysis that gave us the confidence to determine that this project qualified for a class 32 in fill exemption. So I just want to clarify that this project is utilizing the state density bonus law in addition to a conditional use. So the more affordable units you get, the additional waivers and incentives come along with that. The density bonus does grant pretty much the bulk and massing of the building. So, you know, if the additional conditional use density bonus did go away, we'd still have the same size building, just lower number of units. Did want to make a point that this project you're seeing 27% of affordable units as part of that project. We usually see 10 or 15% of those units would be affordable. So this is a rather large affordability on this building. But again, the density bonus controls the bulk and massing of the building not the conditional use. So larger building with more units or same building with less units, just depending on how that goes. But that pretty much is what I heard from the public, but I'm happy to answer any other questions or concerns. Thank you.\n",
      "Speaker 04:  for that clarification. I know we have a number of new commissioners here so please do ask questions to staff in regards to the Densley bonus program if you have any questions. So at this time I like to open deliberation and open it up to my fellow commissioners. Are there any specific questions or comments you'd like to make?\n",
      "Speaker 38:  Just one question. Jacob Newton. Yeah, Jacob Newton, one question for staff. When you do mention that it would be the same size building with less units. I'm assuming that it would also be less affordable units in that mixture. If the unit number was reduced.\n",
      "Speaker 04:  Jacob Newton.\n",
      "Speaker 35:  Yes, Commissioner, that's correct. This is Heather Blamers. We would have 85 units total with eight low income units.\n",
      "Speaker 38:  Thank you.\n",
      "Speaker 03:  Thank you.\n",
      "Speaker 39:  Okay, yes, three of the trees are going to be relocated, and two of the trees are not in good condition, and therefore they'll be removed.\n",
      "Speaker 03:  So three of the large sickle morph is that?\n",
      "Speaker 39:  Thank you.\n",
      "Speaker 00:  And this is Lisa Weber. It does appear that the applicant's representative is approaching, perhaps the applicant can address that. And speaks specifically to the sick and more trees.\n",
      "Speaker 12:  Yes, I will speak to the Sycamore trees. So the Sycamore trees are beautiful trees. They are not protected trees. The protected tree ordinance states that trees that were clearly planted as part of a planting program and are not naturally occurring do not fall within the definition of protected trees. I do want to say we take the trees very seriously. That's why we're planting more. But there is evidence included in the updated tree report that it shows a planting plan submitted as part of permits that the old tenets planted the trees about you know ten to twenty years ago. So they're not they don't actually fall within the protected tree ordinance.\n",
      "Speaker 03:  And so you are replacing\n",
      "Speaker 12:  That's right. We'll be planting three new ones to replace the healthy, the three healthy sick and more trees that exist on site, but they do want to emphasize. They were not determined to be protected trees and that was a determination made by the Urban Forestry Department upon review of the updated tree report.\n",
      "Speaker 03:  Okay, thank you. And while you're there, in terms of the...\n",
      "Speaker 12:  Yeah, so I can talk, speak to the composition. For the square footage sizes, I'll have the architect actually speak directly to that, because they have a bunch of different unit types and I don't want to get that wrong. So overall unit mix out of 184 units, 86 are studios, 73 are one bedrooms, 21 are two bedrooms, and four of them are three bedrooms. Our affordable unit mix is proportionate to what's represented among the overall unit mix. So, you know, we end up with a proportionate number of studios, one bedrooms, two bedrooms, and three bedroom units among the affordables. And then unit sizes.\n",
      "Speaker 34:  Hello Mark Laman Architect on the project. So the studio units range from around 450 square feet to 600 square feet, mostly in the lower square footed range.\n",
      "Speaker 03:  Okay, thank you. And there was a comment, I believe in the...\n",
      "Speaker 35:  This is Heather Gleimers. So that would apply to all of the affordable units. We don't actually make that determination. Yeah, it's handled outside of the planning process with the housing department. And we would never know which units are going to be reserved for affordable households.\n",
      "Speaker 03:  Okay, thank you. And then well the sponsor is still there. So with regard to those extremely low and very low, is there any?\n",
      "Speaker 12:  Yes, actually, and this is the process I myself had to investigate. You know, I worked in homeless services for a long time and I never worked on this side of it. But for the very low income units, the application process is actually much the same as applying for any other apartment unit. It's just that when the developer chooses someone to live in those units, they will be making sure that they don't make above a certain amount rather than what is typically the case. And also the developer for this project has already agreed to accept Section 8 vouchers for the market rate and the affordable units. We recognize the need for Section 8 to be accepted. There's a huge waiting list of people in Los Angeles who have Section 8 vouchers but can't find a landlord to accept them so that is something that we're planning to do here as well.\n",
      "Speaker 03:  Thank you.\n",
      "Speaker 04:  Karen Mack.\n",
      "Speaker 02:  Let me just ask the questions. So I thought the housing department meant maintain the list.\n",
      "Speaker 12:  Yeah, so that's what our outreach is focused on. So the housing department has an affordable housing portal. You can go there. You don't have to sign up for the portal to get notified or to search for affordable units. You do have to sign up to get notified. So the sign-up process is pretty simple. It's like signing up for a Gmail account. You put down some basic contact information. And then you indicate which projects you would like to be notified of updates on. So when the project is built, folks who've signed up to get notifications of that will get an email or a phone call from the registry and that's how that's that the list that the housing has for those units. And then that kind of gives folks a leg up to be able to know hey it's time to apply for these units and that's really the best we can do and trying to make sure that that people folks who are interested have access to to the units.\n",
      "Speaker 02:  So I just have to say this project is painful.\n",
      "Speaker 04:  Would you be able to speak in the microphone? Thank you.\n",
      "Speaker 02:  Thank you. You can hear me now, but it feels like the mic isn't on. It sounds weak.\n",
      "Speaker 04:  It sounds weak so you could just speak a little louder, please.\n",
      "Speaker 02:  Thank you.\n",
      "Speaker 04:  Go ahead. Congratulations.\n",
      "Speaker 03:  I'm sorry, I had one more design question on the garage and I believe it's the\n",
      "Speaker 34:  Yes, there is screening.\n",
      "Speaker 03:  I couldn't tell from the day.\n",
      "Speaker 34:  There's decorative screening on all the garage openings along and then the entire base is flanked by different varying levels of planting with public bench seating.\n",
      "Speaker 03:  you\n",
      "Speaker 02:  I just want to add that that is one of the successes of the Vienna model is that it is mixed income housing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker 04:  Yes, this is Caroline Cho. I would also agree that, you know, to Commissioner Newton's point that, you know, we're getting more units here and we're getting more affordable housing. And certainly there is no perfect answer or no perfect solution. But certainly I'm also for the mixed income housing, I believe. It allows for everybody to access various amenities that certain projects may not have. If it were separate and so, certainly, although I understand change is difficult, I think that we'll see.\n",
      "Speaker 36:  Sissy Alamos for the record, just a friendly reminder, there is a technical modification to adopt with it emotion.\n",
      "Speaker 04:  Thank you.\n",
      "Speaker 02:  I'm always like, oh, I gotta do it right now.\n",
      "Speaker 04:  Karen Mack.\n",
      "Speaker 02:  I move approval. Do I need to say the case number?\n",
      "Speaker 04:  Thank you.\n",
      "Speaker 02:  Thank you.\n",
      "Speaker 04:  for a second.\n",
      "Speaker 38:  Mr. Newton, second.\n",
      "Speaker 36:  to see that we have a first and a second. So see the lemma's further record. Commissioner Mack.\n",
      "Speaker 02:  Yes.\n",
      "Speaker 36:  Commissioner Noonan.\n",
      "Speaker 38:  Yes.\n",
      "Speaker 36:  Commissioner Lyshay? Yes. Commissioner Zamora?\n",
      "Speaker 38:  you\n",
      "Speaker 03:  Yes.\n",
      "Speaker 36:  Commissioner Vice President Cho? Yes. And the motion carries.\n",
      "Speaker 04:  Thank you and there being no further business this meeting is now adjourned and the time is 1115. Thank you\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the audio file\n",
    "print(\"loading audio file\")\n",
    "# waveform, sample_rate = torchaudio.load(audio_file)\n",
    "\n",
    "# audio = AudioSegment.from_mp3(audio_file)\n",
    "waveform, sample_rate = librosa.load(audio_file, sr=16000)  # Load and resample to 16kHz\n",
    "\n",
    "\n",
    "\n",
    "# Process each segment and transcribe\n",
    "transcriptions = []\n",
    "print(\"processing segments\")\n",
    "\n",
    "previous_speaker = None\n",
    "current_speaker_text = \"\"\n",
    "speaker_ls = []\n",
    "speaker_text_ls = []\n",
    "for segment in diarization.itertracks(yield_label=True):\n",
    "    start_time = segment[0].start\n",
    "    end_time = segment[0].end\n",
    "    speaker_label = segment[2]\n",
    "    \n",
    "    # Extract the segment from the waveform\n",
    "    # start_sample = int(start_time * sample_rate)\n",
    "    # end_sample = int(end_time * sample_rate)\n",
    "    # segment_waveform = waveform[:, start_sample:end_sample]\n",
    "    # segment_waveform = waveform[start_time:end_time]\n",
    "        # Convert time to sample indices\n",
    "    start_sample = int(start_time * sample_rate)\n",
    "    end_sample = int(end_time * sample_rate)\n",
    "    \n",
    "    # Ensure indices are within bounds\n",
    "    start_sample = max(0, start_sample)\n",
    "    end_sample = min(len(waveform), end_sample)\n",
    "    \n",
    "    # Extract the segment from the waveform\n",
    "    segment_waveform = waveform[start_sample:end_sample]\n",
    "\n",
    "\n",
    "    transcription = pipe(segment_waveform)\n",
    "    # transcription = result[\"text\"]\n",
    "\n",
    "    # Convert the segment to text using Whisper\n",
    "    # transcription = whisper_model(segment_waveform.squeeze().numpy(), return_timestamps=False)\n",
    "    current_speaker = speaker_label.split('_')[-1]\n",
    "    \n",
    "    # Handle the first speaker\n",
    "    if previous_speaker is None:\n",
    "        current_speaker_text = transcription['text']\n",
    "\n",
    "\n",
    "    elif current_speaker != previous_speaker:\n",
    "        # Append the previous speaker's text if it exists\n",
    "        if current_speaker_text:\n",
    "            speaker_ls.append(int(previous_speaker.split('_')[-1]))\n",
    "            speaker_text_ls.append(current_speaker_text)\n",
    "            # transcriptions.append(f\"Speaker {previous_speaker.split('_')[-1]}: {current_speaker_text}\")\n",
    "        current_speaker_text = transcription['text']\n",
    "        print(f\"Speaker {speaker_label.split('_')[-1]}: {transcription['text']}\")\n",
    "    else:\n",
    "        current_speaker_text += \" \" + transcription['text']\n",
    "\n",
    "    previous_speaker = current_speaker\n",
    "\n",
    "    # Handle the last speaker after the loop\n",
    "if current_speaker_text:\n",
    "    # transcriptions.append(f\"Speaker {current_speaker}: {current_speaker_text}\")\n",
    "    speaker_ls.append(int(current_speaker.split('_')[-1]))\n",
    "    speaker_text_ls.append(current_speaker_text)\n",
    "\n",
    "# # Print the transcriptions\n",
    "# for transcription in transcriptions:\n",
    "#     print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Thank you.  With that, we will move on to ite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>Good morning commissioners. I'm Kevin Golden,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>Morning commissioners, Heather Bliemers, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>Thank you.  And now what I will do is proceed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Thank you so much. We will now hear from the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>36</td>\n",
       "      <td>Commissioner Lyshay? Yes. Commissioner Zamora?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>38</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>3</td>\n",
       "      <td>Yes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>36</td>\n",
       "      <td>Commissioner Vice President Cho? Yes. And the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>4</td>\n",
       "      <td>Thank you and there being no further business...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     speaker                                               text\n",
       "0          4   Thank you.  With that, we will move on to ite...\n",
       "1         39   Good morning commissioners. I'm Kevin Golden,...\n",
       "2         35   Morning commissioners, Heather Bliemers, the ...\n",
       "3         39   Thank you.  And now what I will do is proceed...\n",
       "4          4   Thank you so much. We will now hear from the ...\n",
       "..       ...                                                ...\n",
       "251       36     Commissioner Lyshay? Yes. Commissioner Zamora?\n",
       "252       38                                                you\n",
       "253        3                                               Yes.\n",
       "254       36   Commissioner Vice President Cho? Yes. And the...\n",
       "255        4   Thank you and there being no further business...\n",
       "\n",
       "[256 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"speaker\": speaker_ls,\n",
    "    \"text\": speaker_text_ls\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(audio_file.replace('.wav', '') + \".csv\", index=False)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
