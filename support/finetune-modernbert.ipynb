{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from huggingface_hub import HfFolder\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Thank you James, me, congratulations. Thank y...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>you</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>That was a bad joke. We should go out to lunc...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>you  We should go out.  you</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>We've been waiting all day to hear from you, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>4</td>\n",
       "      <td>you</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>8</td>\n",
       "      <td>you</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>4</td>\n",
       "      <td>Thank you.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>8</td>\n",
       "      <td>Commissioner Chun Kim, so we're going to wait...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>4</td>\n",
       "      <td>Thank you.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     speaker                                               text  label\n",
       "0          2   Thank you James, me, congratulations. Thank y...    NaN\n",
       "1          8                                                you    NaN\n",
       "2          2   That was a bad joke. We should go out to lunc...    NaN\n",
       "3          8                        you  We should go out.  you    NaN\n",
       "4          2   We've been waiting all day to hear from you, ...    NaN\n",
       "..       ...                                                ...    ...\n",
       "305        4                                                you    NaN\n",
       "306        8                                                you    NaN\n",
       "307        4                                         Thank you.    NaN\n",
       "308        8   Commissioner Chun Kim, so we're going to wait...    NaN\n",
       "309        4                                         Thank you.    NaN\n",
       "\n",
       "[310 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_folder = \"labeled\"\n",
    "datasets = [\"06-13-2013audio_08DIR12-2218_labeled.csv\", \"09-07-2017 audio_6 APCNV-2016-565_labeled.csv\", \"09-12-2017audio_6 ZA-2017-210-CU-1A_labeled.csv\"]\n",
    "\n",
    "#combine all data into singular dataframe\n",
    "#TODO: with actual deployment should directly load into dataloader\n",
    "labeled_df = pd.DataFrame()\n",
    "\n",
    "for data_file in datasets:\n",
    "  file_path = dataset_folder + \"/\" + data_file\n",
    "  data_file_df = pd.read_csv(file_path)\n",
    "  labeled_df = pd.concat([labeled_df, data_file_df], ignore_index=True)\n",
    "\n",
    "labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Dataset:\n",
      "Dataset({\n",
      "    features: ['text', 'label', '__index_level_0__'],\n",
      "    num_rows: 16\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# relabel labels\n",
    "\n",
    "# Replace NaN values in 'label' column with 2\n",
    "labeled_df['label'] = labeled_df['label'].fillna(2)\n",
    "# Drop the speaker column\n",
    "labeled_df = labeled_df.drop('speaker', axis=1)\n",
    "# Drop the index column\n",
    "# labeled_df = labeled_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "#do test train split - make sure the test set is 20/20/40\n",
    "#-1 is oppose, 1 is support, NaN is neither\n",
    "#want 0 oppose, 1 support, 2 neither\n",
    "\n",
    "# Convert NaN to 2 (neither), -1 to 0 (oppose), 1 stays as 1 (support)\n",
    "labeled_df['label'] = labeled_df['label'].map({-1: 0, 1: 1, 2:2})\n",
    "\n",
    "# create test and trainh set\n",
    "test_df = pd.concat([\n",
    "    labeled_df[labeled_df['label'] == 0].sample(n=3, random_state=42),\n",
    "    labeled_df[labeled_df['label'] == 1].sample(n=3, random_state=42), \n",
    "    labeled_df[labeled_df['label'] == 2].sample(n=10, random_state=42)\n",
    "])\n",
    "\n",
    "train_df = labeled_df.drop(test_df.index)\n",
    "\n",
    "\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "\n",
    "split_dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "print(\"\\nTest Dataset:\")\n",
    "print(split_dataset[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"answerdotai/ModernBERT-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2dcbcecd304937aa34a8d9a3b7e5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/294 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eecf34ba6ad04a72abe1731ae73ca4c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['labels', 'input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True, return_tensors=\"pt\")\\\n",
    "    \n",
    "if \"label\" in split_dataset[\"train\"].features.keys():\n",
    "    split_dataset =  split_dataset.rename_column(\"label\", \"labels\") # to match Trainer\n",
    "tokenized_dataset = split_dataset.map(tokenize, batched=True, remove_columns=[\"text\", \"__index_level_0__\"])\n",
    " \n",
    "tokenized_dataset[\"train\"].features.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model_id = \"answerdotai/ModernBERT-base\"\n",
    " \n",
    "labels = tokenized_dataset[\"train\"].features[\"labels\"]\n",
    "num_labels = 3  # Binary classification based on the data\n",
    "label2id = {\"0\": \"0\", \"1\": \"1\", \"2\":\"2\"}\n",
    "id2label = {\"0\": \"0\", \"1\": \"1\", \"2\": \"2\"}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id, num_labels=num_labels, label2id=label2id, id2label=id2label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    score = f1_score(\n",
    "            labels, predictions, labels=labels, pos_label=1, average=\"weighted\"\n",
    "        )\n",
    "    return {\"f1\": float(score) if score == 1 else score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mpham/venvs/modernbert_env/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 5:40:39, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.275486</td>\n",
       "      <td>0.716102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.785093</td>\n",
       "      <td>0.716102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.166787</td>\n",
       "      <td>0.651890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.904066</td>\n",
       "      <td>0.767232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.940097</td>\n",
       "      <td>0.767232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError(\"HTTPSConnectionPool(host='hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com', port=443): Max retries exceeded with url: /repos/36/af/36af92bf533b205e32a4a4e924649285a3d2a9abb75393b6eb34158ac8fade73/30b4b4dbc49966bbea6192556e98b0eaa796e1655c75e9e5ff6c0f9dba09f27a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250210T235603Z&X-Amz-Expires=86400&X-Amz-Signature=02791d90d2569febe3e8d4e02acfb1ae955da4a6e0d33fbebbff043c36713b60&X-Amz-SignedHeaders=host&partNumber=1&uploadId=4YLKVLZRQCI_n0TNeBOsaAQsnMtwzCBAsJPWYSt2u97d6DrFDebjDzaxZ2lkmh3p0Xw5lYPSYMAsWdtKLa.g3hsA42liMD19NaYbg55uv1sWB4CGNWqwgsS5vSn6GM9F&x-id=UploadPart (Caused by SSLError(SSLError(5, '[SYS] unknown error (_ssl.c:2427)')))\"), '(Request ID: bee9238b-3407-43f6-aed6-ad7491e71599)')' thrown while requesting PUT https://hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com/repos/36/af/36af92bf533b205e32a4a4e924649285a3d2a9abb75393b6eb34158ac8fade73/30b4b4dbc49966bbea6192556e98b0eaa796e1655c75e9e5ff6c0f9dba09f27a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250210T235603Z&X-Amz-Expires=86400&X-Amz-Signature=02791d90d2569febe3e8d4e02acfb1ae955da4a6e0d33fbebbff043c36713b60&X-Amz-SignedHeaders=host&partNumber=1&uploadId=4YLKVLZRQCI_n0TNeBOsaAQsnMtwzCBAsJPWYSt2u97d6DrFDebjDzaxZ2lkmh3p0Xw5lYPSYMAsWdtKLa.g3hsA42liMD19NaYbg55uv1sWB4CGNWqwgsS5vSn6GM9F&x-id=UploadPart\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com', port=443): Max retries exceeded with url: /repos/36/af/36af92bf533b205e32a4a4e924649285a3d2a9abb75393b6eb34158ac8fade73/edfb63c3f8a4ed1a907e8876282f9eadf9049ec4f87159386f7d6b2319be03f9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250211%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250211T020509Z&X-Amz-Expires=86400&X-Amz-Signature=c6a05974d3adf726ddc4267988d49aa09ec75401351ca576c7d88c5770a16b0d&X-Amz-SignedHeaders=host&partNumber=1&uploadId=ujfPKJo.WZGmXGh9z1heTeSCH72vHaXEWZLWxTDhx8XI5miRkYAc1aV1kGmsferNTAarRLr.TBBm1HcbYoBDPYfWC8k7.M8ezN_vvLGsQq2zQCUOmCk6xirSKcoPnTIW&x-id=UploadPart (Caused by SSLError(SSLError(5, '[SYS] unknown error (_ssl.c:2427)')))\"), '(Request ID: 22f3001a-fc6a-4455-8b85-6b664f13baab)')' thrown while requesting PUT https://hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com/repos/36/af/36af92bf533b205e32a4a4e924649285a3d2a9abb75393b6eb34158ac8fade73/edfb63c3f8a4ed1a907e8876282f9eadf9049ec4f87159386f7d6b2319be03f9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250211%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250211T020509Z&X-Amz-Expires=86400&X-Amz-Signature=c6a05974d3adf726ddc4267988d49aa09ec75401351ca576c7d88c5770a16b0d&X-Amz-SignedHeaders=host&partNumber=1&uploadId=ujfPKJo.WZGmXGh9z1heTeSCH72vHaXEWZLWxTDhx8XI5miRkYAc1aV1kGmsferNTAarRLr.TBBm1HcbYoBDPYfWC8k7.M8ezN_vvLGsQq2zQCUOmCk6xirSKcoPnTIW&x-id=UploadPart\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=50, training_loss=0.1247582721710205, metrics={'train_runtime': 20615.5887, 'train_samples_per_second': 0.071, 'train_steps_per_second': 0.002, 'total_flos': 583099284705840.0, 'train_loss': 0.1247582721710205, 'epoch': 5.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training args for Mx metal series macbook\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir= \"ModernBERT-domain-classifier\",\n",
    "#     per_device_train_batch_size=32,\n",
    "#     per_device_eval_batch_size=16,\n",
    "#     learning_rate=5e-5,\n",
    "#         num_train_epochs=5,\n",
    "#     bf16=True, # bfloat16 training \n",
    "#     optim=\"adamw_torch_fused\", # improved optimizer \n",
    "#     # logging & evaluation strategies\n",
    "#     logging_strategy=\"steps\",\n",
    "#     logging_steps=100,\n",
    "#     eval_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     save_total_limit=2,\n",
    "#     load_best_model_at_end=True,\n",
    "#     use_mps_device=True,\n",
    "#     metric_for_best_model=\"f1\",\n",
    "#     # push to hub parameters\n",
    "#     push_to_hub=True,\n",
    "#     hub_strategy=\"every_save\",\n",
    "#     hub_token=HfFolder.get_token(),\n",
    "# )\n",
    "\n",
    "# training args for Intel silicon series macbook\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= \"ModernBERT-domain-classifier\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=5,\n",
    "    bf16=False,\n",
    "    optim=\"adamw_hf\",  # Changed to standard optimizer\n",
    "    # logging & evaluation strategies\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    # push to hub parameters\n",
    "    push_to_hub=True,\n",
    "    hub_strategy=\"every_save\",\n",
    "    hub_token=HfFolder.get_token(),\n",
    ")\n",
    " \n",
    "# trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "#forward inference\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"mpham8/ModernBERT-domain-classifier\")\n",
    "\n",
    "classifier = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': '2', 'score': 0.7018373608589172}, {'label': '2', 'score': 0.9893173575401306}, {'label': '2', 'score': 0.62039715051651}, {'label': '1', 'score': 0.870729923248291}, {'label': '1', 'score': 0.543232798576355}, {'label': '2', 'score': 0.5413481593132019}, {'label': '2', 'score': 0.9983381032943726}, {'label': '2', 'score': 0.9999887943267822}, {'label': '2', 'score': 0.999983549118042}, {'label': '2', 'score': 0.9999817609786987}, {'label': '2', 'score': 0.9999958276748657}, {'label': '2', 'score': 0.9988155364990234}, {'label': '2', 'score': 0.9999511241912842}, {'label': '2', 'score': 0.9399980902671814}, {'label': '2', 'score': 0.7595450282096863}, {'label': '2', 'score': 0.9993185997009277}]\n"
     ]
    }
   ],
   "source": [
    "test_texts = test_df[\"text\"].tolist() \n",
    "predictions = classifier(test_texts)\n",
    "print(predictions)\n",
    "\n",
    "# Get true labels from test set\n",
    "truelabels_ls = test_df[\"label\"].tolist()\n",
    "predlabels_ls = [int(pred[\"label\"][-1]) for pred in predictions]  # Extracts the label number from \"LABEL_X\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mpham/venvs/modernbert_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/mpham/venvs/modernbert_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/mpham/venvs/modernbert_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/mpham/venvs/modernbert_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "Precision: 0.63\n",
      "Recall: 0.75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.71</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.67</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  support\n",
       "0                  0.00    0.00      0.00     3.00\n",
       "1                  1.00    0.67      0.80     3.00\n",
       "2                  0.71    1.00      0.83    10.00\n",
       "accuracy           0.75    0.75      0.75     0.75\n",
       "macro avg          0.57    0.56      0.54    16.00\n",
       "weighted avg       0.63    0.75      0.67    16.00"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(truelabels_ls, predlabels_ls)\n",
    "precision = precision_score(truelabels_ls, predlabels_ls, average='weighted')\n",
    "recall = recall_score(truelabels_ls, predlabels_ls, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\") \n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "report = classification_report(truelabels_ls, predlabels_ls, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df = report_df.round(2) \n",
    "\n",
    "report_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label distribution in labeled data:\n",
      "Label 0: 5\n",
      "Label 1: 9\n",
      "Label 2: 296\n"
     ]
    }
   ],
   "source": [
    "# Get counts of each label in labeled_df\n",
    "label_counts = labeled_df['label'].value_counts().sort_index()\n",
    "print(\"\\nLabel distribution in labeled data:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Label {label}: {count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
